{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Демонстрация простой вариационной модели и ее прунинга.\n",
    "\n",
    "**Disclaimer**: могут быть ошибки, кроме того, функии могут быть написаны неоптимально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t \n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pylab as plt\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # cuda or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb5c0025090>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "init_log_sigma = -3.0 # логарифм дисперсии вариационного распределения при инициализации\n",
    "prior_sigma = 1.0 # априорная дисперсия\n",
    "epoch_num = 5 #количество эпох\n",
    "lam = 1.0 # коэффициент перед дивергенцией\n",
    "hidden_num = 10 # количество нейронов на скрытом слое\n",
    "t.manual_seed(42) # задаем значение генератора случайных чисел для повторяемости экспериментов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "train_data = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                                  torchvision.transforms.Lambda(lambda x: x.view(-1))\n",
    "                              ]))\n",
    "\n",
    "test_data = torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                                  torchvision.transforms.Lambda(lambda x: x.view(-1))\n",
    "                              ]))\n",
    "\n",
    "\n",
    "train_loader = t.utils.data.DataLoader(train_data, batch_size=batch_size, pin_memory=True )\n",
    "test_loader = t.utils.data.DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarLayer(nn.Module): # вариационная однослойная сеть\n",
    "    def __init__(self, in_,  out_,   act=F.relu):         \n",
    "        nn.Module.__init__(self)                    \n",
    "        self.mean = nn.Parameter(t.randn(in_, out_, device=device)) # параметры средних\n",
    "        t.nn.init.xavier_uniform(self.mean) \n",
    "        self.log_sigma = nn.Parameter(t.ones(in_, out_, device = device)*init_log_sigma) # логарифм дисперсии\n",
    "        self.mean_b = nn.Parameter(t.randn(out_, device=device)) # то же самое для свободного коэффициента\n",
    "        self.log_sigma_b = nn.Parameter(t.ones(out_, device=device) * init_log_sigma)\n",
    "                \n",
    "        self.in_ = in_\n",
    "        self.out_ = out_\n",
    "        self.act = act\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if self.training: # во время обучения - сэмплируем из нормального распределения\n",
    "            self.eps_w = t.distributions.Normal(self.mean, t.exp(self.log_sigma))\n",
    "            self.eps_b = t.distributions.Normal(self.mean_b, t.exp(self.log_sigma_b))\n",
    "        \n",
    "            w = self.eps_w.rsample()\n",
    "            b = self.eps_b.rsample()\n",
    "             \n",
    "        else:  # во время контроля - смотрим средние значения параметра        \n",
    "            w = self.mean \n",
    "            b = self.mean_b\n",
    "            \n",
    "        # функция активации \n",
    "        return self.act(t.matmul(x, w)+b)\n",
    "\n",
    "    def KLD(self):        \n",
    "        # подсчет дивергенции\n",
    "        size = self.in_, self.out_\n",
    "        out = self.out_\n",
    "        self.eps_w = t.distributions.Normal(self.mean, t.exp(self.log_sigma))\n",
    "        self.eps_b = t.distributions.Normal(self.mean_b,  t.exp(self.log_sigma_b))\n",
    "        self.h_w = t.distributions.Normal(t.zeros(size, device=device), t.ones(size, device=device)*prior_sigma)\n",
    "        self.h_b = t.distributions.Normal(t.zeros(out, device=device), t.ones(out, device=device)*prior_sigma)                \n",
    "        k1 = t.distributions.kl_divergence(self.eps_w,self.h_w).sum()        \n",
    "        k2 = t.distributions.kl_divergence(self.eps_b,self.h_b).sum()        \n",
    "        return k1+k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarSeqNet(nn.Sequential):    \n",
    "    # класс-обертка на случай, если у нас многослойная нейронная сеть\n",
    "    def KLD(self):\n",
    "        k = 0\n",
    "        for l in self:\n",
    "            k+=l.KLD()\n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:5: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of net: 0 tensor(236673.2031) tensor(216732.5312) tensor(19940.6738)\n",
      "Number of net: 0 tensor(276531.5625) tensor(256590.8750) tensor(19940.6738)\n",
      "Number of net: 1 tensor(98752.8281) tensor(79030.0703) tensor(19722.7539)\n",
      "Number of net: 1 tensor(76994.5469) tensor(57395.4727) tensor(19599.0703)\n",
      "end of epoch:  0\n",
      "Number of net: tensor(20858.7695, grad_fn=<AddBackward0>)\n",
      "Number of net: tensor(19754.3574, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(230122.8281) tensor(210182.1562) tensor(19940.6738)\n",
      "Number of net: 0 tensor(297094.1875) tensor(277153.5000) tensor(19940.6738)\n",
      "Number of net: 1 tensor(48348.9492) tensor(28784.7070) tensor(19564.2422)\n",
      "Number of net: 1 tensor(54945.3359) tensor(35405.3906) tensor(19539.9453)\n",
      "end of epoch:  1\n",
      "Number of net: tensor(20858.7695, grad_fn=<AddBackward0>)\n",
      "Number of net: tensor(19637.5391, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(264994.7188) tensor(245054.0312) tensor(19940.6738)\n",
      "Number of net: 0 tensor(242112.6719) tensor(222172.) tensor(19940.6738)\n",
      "Number of net: 1 tensor(52481.2617) tensor(32985.3711) tensor(19495.8906)\n",
      "Number of net: 1 tensor(48420.2109) tensor(28955.1211) tensor(19465.0879)\n",
      "end of epoch:  2\n",
      "Number of net: tensor(20858.7695, grad_fn=<AddBackward0>)\n",
      "Number of net: tensor(19545.0215, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(239554.1562) tensor(219613.4844) tensor(19940.6738)\n",
      "Number of net: 0 tensor(289956.9688) tensor(270016.2812) tensor(19940.6738)\n",
      "Number of net: 1 tensor(40241.7578) tensor(20829.7480) tensor(19412.0078)\n",
      "Number of net: 1 tensor(50700.5156) tensor(31324.3203) tensor(19376.1953)\n",
      "end of epoch:  3\n",
      "Number of net: tensor(20858.7695, grad_fn=<AddBackward0>)\n",
      "Number of net: tensor(19445.3633, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(292853.3750) tensor(272912.6875) tensor(19940.6738)\n",
      "Number of net: 0 tensor(286884.7500) tensor(266944.0625) tensor(19940.6738)\n",
      "Number of net: 1 tensor(38800.2539) tensor(19484.1484) tensor(19316.1055)\n",
      "Number of net: 1 tensor(63803.5781) tensor(44527.3945) tensor(19276.1855)\n",
      "end of epoch:  4\n",
      "Number of net: tensor(20858.7695, grad_fn=<AddBackward0>)\n",
      "Number of net: tensor(19350.8418, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# рассмотрим для примера сеть, состояющую из двух слоев\n",
    "# второй слой - softmax. По сути для обучения задавать активацию явно не нужно, она забита в nn.CrossEntropyLoss\n",
    "nets=[]\n",
    "for i in range(2):\n",
    "    nets.append(VarSeqNet(VarLayer(784,  hidden_num), VarLayer(hidden_num, 10, act=lambda x:x)))\n",
    "    optimizer = optim.Adam(nets[i].parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss() \n",
    "loss_graf=[[],[]]\n",
    "out = [None, None]\n",
    "out_loss = [None, None]\n",
    "kld = [None, None]\n",
    "loss = [None, None]\n",
    "\n",
    "for epoch in range(epoch_num):             \n",
    "    for i,net in enumerate(nets):\n",
    "        for id, (x,y) in enumerate(train_loader):  \n",
    "            id+=1\n",
    "            if device == 'cuda':\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()            \n",
    "            optimizer.zero_grad()   \n",
    "            out[i] = net(x)\n",
    "            # правдоподобие должно суммироваться по всей обучающей выборке\n",
    "            # в случае батчей - она приводится к тому же порядку \n",
    "            out_loss[i] = loss_fn(out[i], y)* len(train_data)         \n",
    "            kld[i] =  net.KLD() * lam        \n",
    "            loss[i] = (out_loss[i]+kld[i])       \n",
    "            if id %100 == 0:           \n",
    "                print (\"Number of net:\",i, loss[i].data, out_loss[i].data, kld[i].data)            \n",
    "            loss[i].backward()       \n",
    "            clip_grad_value_(net.parameters(), 1.0) # для стабильности градиента. С этим можно играться\n",
    "            optimizer.step()\n",
    "    print ('end of epoch: ', epoch)   \n",
    "    for i,net in enumerate(nets):\n",
    "        net.eval()\n",
    "        kld[i] =  net.KLD()        \n",
    "        loss[i] = kld[i]\n",
    "        for x,y in test_loader:\n",
    "            if device == 'cuda':\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()                    \n",
    "            out[i] = net(x)        \n",
    "            out_loss[i] = loss_fn(out[i], y)* len(train_data)/len(test_data)           \n",
    "            loss[i] += out_loss[i] \n",
    "        net.train()\n",
    "        print ('Number of net:', i, loss[i])\n",
    "        loss_graf[i].append(loss[i].item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20858.76953125, 20858.76953125, 20858.76953125, 20858.76953125, 20858.76953125], [19754.357421875, 19637.5390625, 19545.021484375, 19445.36328125, 19350.841796875]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb53978c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loss_graf)\n",
    "for i,net in enumerate(nets): \n",
    "    plt.plot(loss_graf[i])\n",
    "plt.ylabel('Loss function')\n",
    "plt.xlabel('Number of epoche')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1022\n",
      "0.9963\n"
     ]
    }
   ],
   "source": [
    "def test_acc(): # точность классификации\n",
    "    correct = 0\n",
    "    for i,net in enumerate(nets):\n",
    "        net.eval()\n",
    "        for x,y in test_loader:\n",
    "            if device == 'cuda':\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()     \n",
    "            out[i] = net(x)    \n",
    "            correct += out[i].argmax(1).eq(y).sum().cpu().numpy()\n",
    "        print (correct / len(test_data))\n",
    "test_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# коэффициенты информативности, см. статью practical variational inference\n",
    "# попробуем удалять параметры первого слоя по этому коэффициенту\n",
    "mu = net[0].mean \n",
    "sigma = t.exp(2*net[0].log_sigma)\n",
    "prune_coef = (mu**2/sigma).cpu().detach().numpy() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero params:  tensor(0.9999, device='cuda:0')\n",
      "0.8876\n",
      "nonzero params:  tensor(0.8999, device='cuda:0')\n",
      "0.8888\n",
      "nonzero params:  tensor(0.7999, device='cuda:0')\n",
      "0.8886\n",
      "nonzero params:  tensor(0.6999, device='cuda:0')\n",
      "0.8853\n",
      "nonzero params:  tensor(0.5999, device='cuda:0')\n",
      "0.8778\n",
      "nonzero params:  tensor(0.4999, device='cuda:0')\n",
      "0.8597\n",
      "nonzero params:  tensor(0.3999, device='cuda:0')\n",
      "0.8473\n",
      "nonzero params:  tensor(0.2999, device='cuda:0')\n",
      "0.8424\n",
      "nonzero params:  tensor(0.1999, device='cuda:0')\n",
      "0.8373\n",
      "nonzero params:  tensor(0.0999, device='cuda:0')\n",
      "0.5528\n"
     ]
    }
   ],
   "source": [
    "# будем удалять по 10% от модели и смотреть качество\n",
    "sorted_coefs = np.sort(prune_coef.flatten())\n",
    "for i in range(10):\n",
    "    ids = (prune_coef <= sorted_coefs[round(i/10*len(sorted_coefs))]) \n",
    "    net[0].mean.data*=(1-t.tensor(ids*1.0, device=device, dtype=t.float))\n",
    "    print ('nonzero params: ', (abs(net[0].mean)>0).float().mean())\n",
    "    (test_acc())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero params:  tensor(0.0999, device='cuda:0')\n",
      "0.5528\n",
      "nonzero params:  tensor(0.0899, device='cuda:0')\n",
      "0.514\n",
      "nonzero params:  tensor(0.0798, device='cuda:0')\n",
      "0.4514\n",
      "nonzero params:  tensor(0.0699, device='cuda:0')\n",
      "0.4412\n",
      "nonzero params:  tensor(0.0598, device='cuda:0')\n",
      "0.3953\n",
      "nonzero params:  tensor(0.0499, device='cuda:0')\n",
      "0.3444\n",
      "nonzero params:  tensor(0.0399, device='cuda:0')\n",
      "0.3026\n",
      "nonzero params:  tensor(0.0298, device='cuda:0')\n",
      "0.2887\n",
      "nonzero params:  tensor(0.0199, device='cuda:0')\n",
      "0.2417\n",
      "nonzero params:  tensor(0.0098, device='cuda:0')\n",
      "0.2247\n",
      "nonzero params:  tensor(0., device='cuda:0')\n",
      "0.101\n"
     ]
    }
   ],
   "source": [
    "# проверяем, что фокусов тут нет, удаляем оставшиеся 10%\\\n",
    "for i in range(10):\n",
    "    ids = (prune_coef <= sorted_coefs[round((0.9+i/100)*len(sorted_coefs))]) \n",
    "    net[0].mean.data*=(1-t.tensor(ids*1.0, device=device, dtype=t.float))\n",
    "    print ('nonzero params: ', (abs(net[0].mean)>0).float().mean())\n",
    "    (test_acc())\n",
    "    \n",
    "net[0].mean.data*=0\n",
    "print ('nonzero params: ', (abs(net[0].mean)>0).float().mean())\n",
    "(test_acc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
