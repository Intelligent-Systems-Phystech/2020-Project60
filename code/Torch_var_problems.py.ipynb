{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Демонстрация простой вариационной модели и ее прунинга.\n",
    "\n",
    "**Disclaimer**: могут быть ошибки, кроме того, функии могут быть написаны неоптимально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t \n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pylab as plt\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # cuda or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7364f1fe10>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "init_log_sigma = -3.0 # логарифм дисперсии вариационного распределения при инициализации\n",
    "prior_sigma = 1.0 # априорная дисперсия\n",
    "epoch_num = 5 #количество эпох\n",
    "lamb = [0, 0.1, 0.5, 1, 5, 10, 100]\n",
    "# lam = 1.0 # коэффициент перед дивергенцией\n",
    "hidden_num = 10 # количество нейронов на скрытом слое\n",
    "t.manual_seed(42) # задаем значение генератора случайных чисел для повторяемости экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "train_data = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                                  torchvision.transforms.Lambda(lambda x: x.view(-1))\n",
    "                              ]))\n",
    "\n",
    "test_data = torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                                  torchvision.transforms.Lambda(lambda x: x.view(-1))\n",
    "                              ]))\n",
    "\n",
    "\n",
    "train_loader = t.utils.data.DataLoader(train_data, batch_size=batch_size, pin_memory=True )\n",
    "test_loader = t.utils.data.DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarLayer(nn.Module): # вариационная однослойная сеть\n",
    "    def __init__(self, in_,  out_,   act=F.relu):         \n",
    "        nn.Module.__init__(self)                    \n",
    "        self.mean = nn.Parameter(t.randn(in_, out_, device=device)) # параметры средних\n",
    "        t.nn.init.xavier_uniform(self.mean) \n",
    "        self.log_sigma = nn.Parameter(t.ones(in_, out_, device = device)*init_log_sigma) # логарифм дисперсии\n",
    "        self.mean_b = nn.Parameter(t.randn(out_, device=device)) # то же самое для свободного коэффициента\n",
    "        self.log_sigma_b = nn.Parameter(t.ones(out_, device=device) * init_log_sigma)\n",
    "                \n",
    "        self.in_ = in_\n",
    "        self.out_ = out_\n",
    "        self.act = act\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if self.training: # во время обучения - сэмплируем из нормального распределения\n",
    "            self.eps_w = t.distributions.Normal(self.mean, t.exp(self.log_sigma))\n",
    "            self.eps_b = t.distributions.Normal(self.mean_b, t.exp(self.log_sigma_b))\n",
    "        \n",
    "            w = self.eps_w.rsample()\n",
    "            b = self.eps_b.rsample()\n",
    "             \n",
    "        else:  # во время контроля - смотрим средние значения параметра        \n",
    "            w = self.mean \n",
    "            b = self.mean_b\n",
    "            \n",
    "        # функция активации \n",
    "        return self.act(t.matmul(x, w)+b)\n",
    "\n",
    "    def KLD(self):        \n",
    "        # подсчет дивергенции\n",
    "        size = self.in_, self.out_\n",
    "        out = self.out_\n",
    "        self.eps_w = t.distributions.Normal(self.mean, t.exp(self.log_sigma))\n",
    "        self.eps_b = t.distributions.Normal(self.mean_b,  t.exp(self.log_sigma_b))\n",
    "        self.h_w = t.distributions.Normal(t.zeros(size, device=device), t.ones(size, device=device)*prior_sigma)\n",
    "        self.h_b = t.distributions.Normal(t.zeros(out, device=device), t.ones(out, device=device)*prior_sigma)                \n",
    "        k1 = t.distributions.kl_divergence(self.eps_w,self.h_w).sum()        \n",
    "        k2 = t.distributions.kl_divergence(self.eps_b,self.h_b).sum()        \n",
    "        return k1+k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarSeqNet(nn.Sequential):    \n",
    "    # класс-обертка на случай, если у нас многослойная нейронная сеть\n",
    "    def KLD(self):\n",
    "        k = 0\n",
    "        for l in self:\n",
    "            k+=l.KLD()\n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batches(net, loss_fn, optimizer, i):\n",
    "    for id, (x,y) in enumerate(train_loader):  \n",
    "            id+=1\n",
    "            if device == 'cuda':\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()            \n",
    "            optimizer.zero_grad()   \n",
    "            out[i] = net(x)\n",
    "            # правдоподобие должно суммироваться по всей обучающей выборке\n",
    "            # в случае батчей - она приводится к тому же порядку \n",
    "            out_loss[i] = loss_fn(out[i], y)* len(train_data)         \n",
    "            kld[i] =  net.KLD() * lam        \n",
    "            loss[i] = (out_loss[i]+kld[i])       \n",
    "            if id %100 == 0:           \n",
    "                print (\"Number of net:\",i, loss[i].data, out_loss[i].data, kld[i].data)            \n",
    "            loss[i].backward()       \n",
    "            clip_grad_value_(net.parameters(), 1.0) # для стабильности градиента. С этим можно играться\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic(net, loss_fn, i):\n",
    "    net.eval()  \n",
    "    kld[i] =  net.KLD() \n",
    "    loss[i] = kld[i]\n",
    "    for x,y in test_loader:\n",
    "         if device == 'cuda':\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()          \n",
    "    out[i] = net(x)   \n",
    "    out_loss[i] = loss_fn(out[i], y)* len(train_data)/len(test_data)   \n",
    "    #  print(out_loss[i])\n",
    "    # print(loss[i])\n",
    "    loss[i] += out_loss[i]\n",
    "    net.train()\n",
    "    print (loss[i])\n",
    "    return loss[i]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассмотрим для примера сеть, состояющую из двух слоев\n",
    "# второй слой - softmax. По сути для обучения задавать активацию явно не нужно, она забита в nn.CrossEntropyLoss\n",
    "def init_nets():\n",
    "    for i in range(3):\n",
    "        nets.append(VarSeqNet(VarLayer(784,  hidden_num), VarLayer(hidden_num, 10, act=lambda x:x)))\n",
    "        optimizer_nets.append(optim.Adam(nets[i].parameters()))\n",
    "    loss_fn_nets = [nn.CrossEntropyLoss(), nn.CrossEntropyLoss(), nn.CrossEntropyLoss()] \n",
    "    loss_graf=[[],[],[]]\n",
    "    out = [None, None, None]\n",
    "    out_loss = [None, None, None]\n",
    "    kld = [None, None, None]\n",
    "    loss = [None, None, None]\n",
    "\n",
    "def train_nets():\n",
    "    for epoch in range(epoch_num):             \n",
    "        for i,net in enumerate(nets):\n",
    "            train_batches(net,loss_fn_nets[i], optimizer_nets[i],i)\n",
    "        print ('end of epoch: ', epoch)   \n",
    "        for i,net in enumerate(nets):\n",
    "            print(\"Number of net:\",i)        \n",
    "            loss_graf[i].append(statistic(net, loss_fn_nets[i], i))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(loss_graf)\n",
    "def graph_loss_func():\n",
    "    for i,net in enumerate(nets): \n",
    "        plt.plot(loss_graf[i])\n",
    "    plt.ylabel('Loss function')\n",
    "    plt.xlabel('Number of epoche')\n",
    "    plt.show()\n",
    "#print(out_loss)\n",
    "\n",
    "#graph_loss_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(): # точность классификации\n",
    "    acc = []\n",
    "    for i,net in enumerate(nets):\n",
    "        correct = 0\n",
    "        net.eval()\n",
    "        for x,y in test_loader:\n",
    "            if device == 'cuda':\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()     \n",
    "            out[i] = net(x)    \n",
    "            correct += out[i].argmax(1).eq(y).sum().cpu().numpy()\n",
    "        acc.append(correct / len(test_data))\n",
    "    print(sum(acc)/len(acc))   \n",
    "    return(sum(acc)/len(acc))\n",
    "#test_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# коэффициенты информативности, см. статью practical variational inference\n",
    "# попробуем удалять параметры первого слоя по этому коэффициенту\n",
    "\n",
    "def init_coeff():\n",
    "    for i,net in enumerate(nets): \n",
    "        mu.append(net[0].mean) \n",
    "        sigma.append(t.exp(2*net[0].log_sigma))\n",
    "        prune_coef.append((mu[i]**2/sigma[i]).cpu().detach().numpy())\n",
    "    print(prune_coef)\n",
    "\n",
    "#init_coeff()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем удалять по 10% от модели и смотреть качество\n",
    "def delete_10():\n",
    "    flag = 0\n",
    "    print(prune_coef)\n",
    "    for j in range(10):\n",
    "        for i,net in enumerate(nets): \n",
    "            if (flag == 0):\n",
    "                sorted_coefs = np.sort(prune_coef[i].flatten())\n",
    "                flag = 1\n",
    "            ids = (prune_coef[i] <= sorted_coefs[round(j/10*len(sorted_coefs))]) \n",
    "            net[0].mean.data*=(1-t.tensor(ids*1.0, device=device, dtype=t.float))\n",
    "            print ('nonzero params: ', (abs(net[0].mean)>0).float().mean())\n",
    "        acc_delete.append(test_acc())\n",
    "        #(test_acc()) #среднее по всем nets\n",
    "    \n",
    "#delete_10()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph():\n",
    "    proc = [0,10,20,30,40,50,60,70,80,90]\n",
    "    plt.plot(proc, acc_delete)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Procent')\n",
    "\n",
    "# graph()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем, что фокусов тут нет, удаляем оставшиеся 10%\\\n",
    "def delete_last10():\n",
    "    flag = 0\n",
    "    for j in range(10):\n",
    "        for i,net in enumerate(nets): \n",
    "            if (flag == 0):\n",
    "                sorted_coefs = np.sort(prune_coef[i].flatten())\n",
    "                flag = 1\n",
    "            ids = (prune_coef[i] <= sorted_coefs[round((0.9+j/100)*len(sorted_coefs))]) \n",
    "            net[0].mean.data*=(1-t.tensor(ids*1.0, device=device, dtype=t.float))\n",
    "            print ('nonzero params: ', (abs(net[0].mean)>0).float().mean())\n",
    "        (test_acc())\n",
    "    for i,net in enumerate(nets):\n",
    "        net[0].mean.data*=0\n",
    "        print ('nonzero params: ', (abs(net[0].mean)>0).float().mean())\n",
    "    (test_acc())\n",
    "    \n",
    "#delete_last10()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:5: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of net: 0 tensor(125475.1406) tensor(125475.1406) tensor(0.)\n",
      "Number of net: 0 tensor(109208.2266) tensor(109208.2266) tensor(0.)\n",
      "Number of net: 1 tensor(115026.8047) tensor(115026.8047) tensor(0.)\n",
      "Number of net: 1 tensor(77652.9375) tensor(77652.9375) tensor(0.)\n",
      "Number of net: 2 tensor(79912.8203) tensor(79912.8203) tensor(0.)\n",
      "Number of net: 2 tensor(49200.6680) tensor(49200.6680) tensor(0.)\n",
      "end of epoch:  0\n",
      "Number of net: 0\n",
      "tensor(19965.5781, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19975.0859, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19976.5039, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(71032.9375) tensor(71032.9375) tensor(0.)\n",
      "Number of net: 0 tensor(65900.6094) tensor(65900.6094) tensor(0.)\n",
      "Number of net: 1 tensor(63762.8672) tensor(63762.8672) tensor(0.)\n",
      "Number of net: 1 tensor(62077.2812) tensor(62077.2812) tensor(0.)\n",
      "Number of net: 2 tensor(39888.9883) tensor(39888.9883) tensor(0.)\n",
      "Number of net: 2 tensor(38848.3984) tensor(38848.3984) tensor(0.)\n",
      "end of epoch:  1\n",
      "Number of net: 0\n",
      "tensor(19989.0527, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(20014.0234, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(20020.7852, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(53353.6445) tensor(53353.6445) tensor(0.)\n",
      "Number of net: 0 tensor(66311.4922) tensor(66311.4922) tensor(0.)\n",
      "Number of net: 1 tensor(42899.8320) tensor(42899.8320) tensor(0.)\n",
      "Number of net: 1 tensor(33743.2227) tensor(33743.2227) tensor(0.)\n",
      "Number of net: 2 tensor(25309.8008) tensor(25309.8008) tensor(0.)\n",
      "Number of net: 2 tensor(28901.2656) tensor(28901.2656) tensor(0.)\n",
      "end of epoch:  2\n",
      "Number of net: 0\n",
      "tensor(20014.8301, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(20051.9629, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(20061.5977, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(54024.9023) tensor(54024.9023) tensor(0.)\n",
      "Number of net: 0 tensor(64168.1797) tensor(64168.1797) tensor(0.)\n",
      "Number of net: 1 tensor(31971.8281) tensor(31971.8281) tensor(0.)\n",
      "Number of net: 1 tensor(35022.5312) tensor(35022.5312) tensor(0.)\n",
      "Number of net: 2 tensor(29215.8027) tensor(29215.8027) tensor(0.)\n",
      "Number of net: 2 tensor(35462.9141) tensor(35462.9141) tensor(0.)\n",
      "end of epoch:  3\n",
      "Number of net: 0\n",
      "tensor(20042.8496, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(20087., grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(20102.6309, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(54695.7891) tensor(54695.7891) tensor(0.)\n",
      "Number of net: 0 tensor(50773.4727) tensor(50773.4727) tensor(0.)\n",
      "Number of net: 1 tensor(32083.7832) tensor(32083.7832) tensor(0.)\n",
      "Number of net: 1 tensor(34870.3320) tensor(34870.3320) tensor(0.)\n",
      "Number of net: 2 tensor(30335.3691) tensor(30335.3691) tensor(0.)\n",
      "Number of net: 2 tensor(38391.7500) tensor(38391.7500) tensor(0.)\n",
      "end of epoch:  4\n",
      "Number of net: 0\n",
      "tensor(20064.7500, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(20125.1562, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(20141.6973, grad_fn=<AddBackward0>)\n",
      "[array([[1.4010043e+00, 2.7137911e+00, 1.6381659e-02, ..., 3.6149004e+00,\n",
      "        4.8343182e+00, 1.5300672e+00],\n",
      "       [3.0111635e+00, 2.1562635e-03, 2.1129858e+00, ..., 1.8034567e+00,\n",
      "        1.7244297e-01, 8.7147266e-02],\n",
      "       [3.1554158e+00, 8.2346219e-01, 2.0206294e+00, ..., 8.3424139e-01,\n",
      "        4.0154314e+00, 4.7038961e-03],\n",
      "       ...,\n",
      "       [2.9599687e-01, 3.2757528e-04, 1.7003444e+00, ..., 7.3841847e-02,\n",
      "        2.8562112e+00, 5.2063596e-01],\n",
      "       [2.9943055e-03, 3.2606694e-01, 6.9563735e-01, ..., 1.5674820e-02,\n",
      "        4.0393054e-01, 3.3353660e-01],\n",
      "       [5.7617396e-02, 2.3576684e+00, 5.3473061e-01, ..., 2.3268964e+00,\n",
      "        6.5243596e-01, 1.6462015e-01]], dtype=float32), array([[4.73598808e-01, 9.05497670e-01, 2.03734446e+00, ...,\n",
      "        3.29415910e-02, 1.66250062e+00, 2.05904150e+00],\n",
      "       [3.50453210e+00, 3.54794189e-02, 3.17684514e-03, ...,\n",
      "        4.93159324e-01, 7.52730906e-01, 5.43676093e-02],\n",
      "       [4.23604339e-01, 6.95838651e-04, 6.33097172e-01, ...,\n",
      "        3.50775896e-03, 8.69678617e-01, 1.15549915e-01],\n",
      "       ...,\n",
      "       [1.00258434e+00, 2.09508371e-02, 3.85270506e-01, ...,\n",
      "        2.02791619e+00, 1.35532558e+00, 2.21457076e+00],\n",
      "       [2.12049205e-02, 3.37197751e-01, 2.83919668e+00, ...,\n",
      "        2.86576226e-02, 1.59333980e+00, 1.19671881e+00],\n",
      "       [5.53845644e-01, 3.66444349e-01, 1.36459410e-01, ...,\n",
      "        3.05859834e-01, 4.94019650e-02, 2.87548327e+00]], dtype=float32), array([[3.38387072e-01, 1.03284471e-01, 9.52673480e-02, ...,\n",
      "        9.65750098e-01, 1.59280300e+00, 1.72246957e+00],\n",
      "       [2.54450464e+00, 1.12887412e-01, 2.83159949e-02, ...,\n",
      "        1.21034586e+00, 1.70458126e+00, 3.02074289e+00],\n",
      "       [1.14786363e+00, 2.52064645e-01, 3.13814640e+00, ...,\n",
      "        2.71826237e-01, 2.69266814e-01, 9.69826207e-02],\n",
      "       ...,\n",
      "       [2.88116002e+00, 2.31221810e-01, 3.91534060e-01, ...,\n",
      "        7.37853289e-01, 6.30973605e-03, 1.16792381e+00],\n",
      "       [2.19071245e+00, 7.12159206e-04, 6.43401325e-01, ...,\n",
      "        1.91978955e+00, 1.23766754e-02, 1.20990777e+00],\n",
      "       [3.80448177e-02, 1.39310360e+00, 1.63918388e+00, ...,\n",
      "        1.22053914e-01, 3.23847413e-01, 1.05836773e+00]], dtype=float32)]\n",
      "[array([[1.4010043e+00, 2.7137911e+00, 1.6381659e-02, ..., 3.6149004e+00,\n",
      "        4.8343182e+00, 1.5300672e+00],\n",
      "       [3.0111635e+00, 2.1562635e-03, 2.1129858e+00, ..., 1.8034567e+00,\n",
      "        1.7244297e-01, 8.7147266e-02],\n",
      "       [3.1554158e+00, 8.2346219e-01, 2.0206294e+00, ..., 8.3424139e-01,\n",
      "        4.0154314e+00, 4.7038961e-03],\n",
      "       ...,\n",
      "       [2.9599687e-01, 3.2757528e-04, 1.7003444e+00, ..., 7.3841847e-02,\n",
      "        2.8562112e+00, 5.2063596e-01],\n",
      "       [2.9943055e-03, 3.2606694e-01, 6.9563735e-01, ..., 1.5674820e-02,\n",
      "        4.0393054e-01, 3.3353660e-01],\n",
      "       [5.7617396e-02, 2.3576684e+00, 5.3473061e-01, ..., 2.3268964e+00,\n",
      "        6.5243596e-01, 1.6462015e-01]], dtype=float32), array([[4.73598808e-01, 9.05497670e-01, 2.03734446e+00, ...,\n",
      "        3.29415910e-02, 1.66250062e+00, 2.05904150e+00],\n",
      "       [3.50453210e+00, 3.54794189e-02, 3.17684514e-03, ...,\n",
      "        4.93159324e-01, 7.52730906e-01, 5.43676093e-02],\n",
      "       [4.23604339e-01, 6.95838651e-04, 6.33097172e-01, ...,\n",
      "        3.50775896e-03, 8.69678617e-01, 1.15549915e-01],\n",
      "       ...,\n",
      "       [1.00258434e+00, 2.09508371e-02, 3.85270506e-01, ...,\n",
      "        2.02791619e+00, 1.35532558e+00, 2.21457076e+00],\n",
      "       [2.12049205e-02, 3.37197751e-01, 2.83919668e+00, ...,\n",
      "        2.86576226e-02, 1.59333980e+00, 1.19671881e+00],\n",
      "       [5.53845644e-01, 3.66444349e-01, 1.36459410e-01, ...,\n",
      "        3.05859834e-01, 4.94019650e-02, 2.87548327e+00]], dtype=float32), array([[3.38387072e-01, 1.03284471e-01, 9.52673480e-02, ...,\n",
      "        9.65750098e-01, 1.59280300e+00, 1.72246957e+00],\n",
      "       [2.54450464e+00, 1.12887412e-01, 2.83159949e-02, ...,\n",
      "        1.21034586e+00, 1.70458126e+00, 3.02074289e+00],\n",
      "       [1.14786363e+00, 2.52064645e-01, 3.13814640e+00, ...,\n",
      "        2.71826237e-01, 2.69266814e-01, 9.69826207e-02],\n",
      "       ...,\n",
      "       [2.88116002e+00, 2.31221810e-01, 3.91534060e-01, ...,\n",
      "        7.37853289e-01, 6.30973605e-03, 1.16792381e+00],\n",
      "       [2.19071245e+00, 7.12159206e-04, 6.43401325e-01, ...,\n",
      "        1.91978955e+00, 1.23766754e-02, 1.20990777e+00],\n",
      "       [3.80448177e-02, 1.39310360e+00, 1.63918388e+00, ...,\n",
      "        1.22053914e-01, 3.23847413e-01, 1.05836773e+00]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(0.9997)\n",
      "nonzero params:  tensor(0.9999)\n",
      "0.8337666666666667\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.9055)\n",
      "nonzero params:  tensor(0.9010)\n",
      "0.8342333333333333\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.8116)\n",
      "nonzero params:  tensor(0.8084)\n",
      "0.8348666666666666\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.7176)\n",
      "nonzero params:  tensor(0.7254)\n",
      "0.8348000000000001\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.6298)\n",
      "nonzero params:  tensor(0.6372)\n",
      "0.8334\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.5274)\n",
      "nonzero params:  tensor(0.5399)\n",
      "0.8309666666666667\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.4434)\n",
      "nonzero params:  tensor(0.4519)\n",
      "0.8198666666666666\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.3547)\n",
      "nonzero params:  tensor(0.3654)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8154\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.2466)\n",
      "nonzero params:  tensor(0.2716)\n",
      "0.8103666666666666\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.1443)\n",
      "nonzero params:  tensor(0.1723)\n",
      "0.7122666666666667\n",
      "Number of net: 0 tensor(82009.9609) tensor(80021.0391) tensor(1988.9199)\n",
      "Number of net: 0 tensor(66788.3906) tensor(64805.3086) tensor(1983.0801)\n",
      "Number of net: 1 tensor(121627.0391) tensor(119641.6562) tensor(1985.3854)\n",
      "Number of net: 1 tensor(101942.3594) tensor(99966.8438) tensor(1975.5140)\n",
      "Number of net: 2 tensor(112365.3672) tensor(110376.7734) tensor(1988.5911)\n",
      "Number of net: 2 tensor(96911.7031) tensor(94930.4688) tensor(1981.2366)\n",
      "end of epoch:  0\n",
      "Number of net: 0\n",
      "tensor(19810.5703, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19720.6348, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19786.3086, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(50613.1406) tensor(48639.5664) tensor(1973.5729)\n",
      "Number of net: 0 tensor(52721.9453) tensor(50756.7266) tensor(1965.2200)\n",
      "Number of net: 1 tensor(61893.8633) tensor(59934.3672) tensor(1959.4961)\n",
      "Number of net: 1 tensor(52224.4609) tensor(50278.8359) tensor(1945.6256)\n",
      "Number of net: 2 tensor(63141.3711) tensor(61172.1094) tensor(1969.2631)\n",
      "Number of net: 2 tensor(58498.4375) tensor(56538.9531) tensor(1959.4857)\n",
      "end of epoch:  1\n",
      "Number of net: 0\n",
      "tensor(19622.2832, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19404.6133, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19560.3906, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(34339.1719) tensor(32386.3652) tensor(1952.8076)\n",
      "Number of net: 0 tensor(52196.3242) tensor(50249.9375) tensor(1946.3883)\n",
      "Number of net: 1 tensor(49328.5547) tensor(47400.9102) tensor(1927.6454)\n",
      "Number of net: 1 tensor(39669.1328) tensor(37751.2969) tensor(1917.8342)\n",
      "Number of net: 2 tensor(54439.8359) tensor(52494.6016) tensor(1945.2340)\n",
      "Number of net: 2 tensor(37042.5781) tensor(35108.2188) tensor(1934.3607)\n",
      "end of epoch:  2\n",
      "Number of net: 0\n",
      "tensor(19447.3672, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19142.8359, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19304.8047, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(23658.2617) tensor(21718.2969) tensor(1939.9642)\n",
      "Number of net: 0 tensor(46513.8945) tensor(44578.8594) tensor(1935.0355)\n",
      "Number of net: 1 tensor(31641.8125) tensor(29737.1641) tensor(1904.6475)\n",
      "Number of net: 1 tensor(49753.8516) tensor(47854.3086) tensor(1899.5424)\n",
      "Number of net: 2 tensor(32016.7871) tensor(30097.8223) tensor(1918.9642)\n",
      "Number of net: 2 tensor(36129.0938) tensor(34221.4883) tensor(1907.6041)\n",
      "end of epoch:  3\n",
      "Number of net: 0\n",
      "tensor(19337.6836, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18979.1855, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19037.6992, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(26956.0898) tensor(25024.1406) tensor(1931.9498)\n",
      "Number of net: 0 tensor(33015.4531) tensor(31085.9688) tensor(1929.4830)\n",
      "Number of net: 1 tensor(27667.8613) tensor(25772.3770) tensor(1895.4846)\n",
      "Number of net: 1 tensor(24146.5039) tensor(22253.9805) tensor(1892.5234)\n",
      "Number of net: 2 tensor(28506.7031) tensor(26614.5352) tensor(1892.1688)\n",
      "Number of net: 2 tensor(25586.8281) tensor(23706.1250) tensor(1880.7028)\n",
      "end of epoch:  4\n",
      "Number of net: 0\n",
      "tensor(19286.5918, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18915.5020, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18769.6660, grad_fn=<AddBackward0>)\n",
      "[array([[7.5115316e-02, 8.4499426e-02, 3.5677215e-01, ..., 1.8887744e+00,\n",
      "        5.9749633e-01, 2.9982841e+00],\n",
      "       [1.5494627e-01, 1.9593077e+00, 2.5483051e-01, ..., 9.3687189e-01,\n",
      "        1.0172765e+00, 1.7142292e+00],\n",
      "       [9.9500954e-02, 3.3304354e-03, 1.3369464e-02, ..., 3.2659695e+00,\n",
      "        7.0680255e-01, 1.2769516e+00],\n",
      "       ...,\n",
      "       [8.9436626e-01, 3.2976403e+00, 3.8832236e-02, ..., 1.9619293e+00,\n",
      "        2.1142738e-01, 2.6134658e-01],\n",
      "       [2.3011048e+00, 1.7115986e+00, 1.4003086e-01, ..., 2.1681216e+00,\n",
      "        1.1989584e+00, 2.7294245e-02],\n",
      "       [2.2253470e+00, 1.1629119e+00, 2.6197892e-04, ..., 9.2562614e-03,\n",
      "        1.9370541e-02, 3.0815857e-02]], dtype=float32), array([[4.3664578e-02, 2.7345452e-03, 3.1512055e-01, ..., 2.0725932e+00,\n",
      "        1.6510731e-01, 5.4966277e-01],\n",
      "       [1.7688096e+00, 7.3016852e-02, 2.2727592e+00, ..., 1.8903551e-01,\n",
      "        4.4889870e-01, 1.7853690e+00],\n",
      "       [1.6951542e-01, 9.6350364e-02, 7.2916526e-01, ..., 1.0650145e-01,\n",
      "        9.9294311e-01, 3.0470912e+00],\n",
      "       ...,\n",
      "       [1.1049116e+00, 8.7597735e-02, 1.4243303e-01, ..., 1.8954857e-01,\n",
      "        5.1881361e-01, 9.0237811e-02],\n",
      "       [1.2706459e-01, 1.0159812e-01, 1.1192038e+00, ..., 7.7517492e-01,\n",
      "        5.2560743e-02, 9.6241988e-02],\n",
      "       [1.1062942e-01, 1.2676175e-03, 6.4550960e-01, ..., 3.2804477e-01,\n",
      "        2.2131245e-01, 1.2759189e-03]], dtype=float32), array([[1.26617135e-06, 3.78589869e-01, 7.86040947e-02, ...,\n",
      "        2.49391079e+00, 1.20096803e-01, 1.60133350e+00],\n",
      "       [1.02946125e-01, 7.55383790e-01, 8.84873420e-03, ...,\n",
      "        3.56273603e+00, 4.55916002e-02, 2.79703259e+00],\n",
      "       [5.74751338e-03, 7.78896391e-01, 2.11322549e-05, ...,\n",
      "        8.62492263e-01, 1.26355797e-01, 2.20562649e+00],\n",
      "       ...,\n",
      "       [7.46475875e-01, 2.52093196e+00, 9.72419828e-02, ...,\n",
      "        2.81139612e+00, 1.39497286e-02, 5.16471982e-01],\n",
      "       [9.06883717e-01, 3.11944604e+00, 2.09161011e-03, ...,\n",
      "        1.53911054e+00, 8.79330635e-02, 6.07848819e-03],\n",
      "       [1.23745906e+00, 2.20350075e+00, 1.33175194e-01, ...,\n",
      "        1.92003739e+00, 1.99221656e-01, 1.46213353e+00]], dtype=float32)]\n",
      "[array([[7.5115316e-02, 8.4499426e-02, 3.5677215e-01, ..., 1.8887744e+00,\n",
      "        5.9749633e-01, 2.9982841e+00],\n",
      "       [1.5494627e-01, 1.9593077e+00, 2.5483051e-01, ..., 9.3687189e-01,\n",
      "        1.0172765e+00, 1.7142292e+00],\n",
      "       [9.9500954e-02, 3.3304354e-03, 1.3369464e-02, ..., 3.2659695e+00,\n",
      "        7.0680255e-01, 1.2769516e+00],\n",
      "       ...,\n",
      "       [8.9436626e-01, 3.2976403e+00, 3.8832236e-02, ..., 1.9619293e+00,\n",
      "        2.1142738e-01, 2.6134658e-01],\n",
      "       [2.3011048e+00, 1.7115986e+00, 1.4003086e-01, ..., 2.1681216e+00,\n",
      "        1.1989584e+00, 2.7294245e-02],\n",
      "       [2.2253470e+00, 1.1629119e+00, 2.6197892e-04, ..., 9.2562614e-03,\n",
      "        1.9370541e-02, 3.0815857e-02]], dtype=float32), array([[4.3664578e-02, 2.7345452e-03, 3.1512055e-01, ..., 2.0725932e+00,\n",
      "        1.6510731e-01, 5.4966277e-01],\n",
      "       [1.7688096e+00, 7.3016852e-02, 2.2727592e+00, ..., 1.8903551e-01,\n",
      "        4.4889870e-01, 1.7853690e+00],\n",
      "       [1.6951542e-01, 9.6350364e-02, 7.2916526e-01, ..., 1.0650145e-01,\n",
      "        9.9294311e-01, 3.0470912e+00],\n",
      "       ...,\n",
      "       [1.1049116e+00, 8.7597735e-02, 1.4243303e-01, ..., 1.8954857e-01,\n",
      "        5.1881361e-01, 9.0237811e-02],\n",
      "       [1.2706459e-01, 1.0159812e-01, 1.1192038e+00, ..., 7.7517492e-01,\n",
      "        5.2560743e-02, 9.6241988e-02],\n",
      "       [1.1062942e-01, 1.2676175e-03, 6.4550960e-01, ..., 3.2804477e-01,\n",
      "        2.2131245e-01, 1.2759189e-03]], dtype=float32), array([[1.26617135e-06, 3.78589869e-01, 7.86040947e-02, ...,\n",
      "        2.49391079e+00, 1.20096803e-01, 1.60133350e+00],\n",
      "       [1.02946125e-01, 7.55383790e-01, 8.84873420e-03, ...,\n",
      "        3.56273603e+00, 4.55916002e-02, 2.79703259e+00],\n",
      "       [5.74751338e-03, 7.78896391e-01, 2.11322549e-05, ...,\n",
      "        8.62492263e-01, 1.26355797e-01, 2.20562649e+00],\n",
      "       ...,\n",
      "       [7.46475875e-01, 2.52093196e+00, 9.72419828e-02, ...,\n",
      "        2.81139612e+00, 1.39497286e-02, 5.16471982e-01],\n",
      "       [9.06883717e-01, 3.11944604e+00, 2.09161011e-03, ...,\n",
      "        1.53911054e+00, 8.79330635e-02, 6.07848819e-03],\n",
      "       [1.23745906e+00, 2.20350075e+00, 1.33175194e-01, ...,\n",
      "        1.92003739e+00, 1.99221656e-01, 1.46213353e+00]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(0.9999)\n",
      "0.8829333333333333\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.9034)\n",
      "nonzero params:  tensor(0.8776)\n",
      "0.8830666666666666\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.7976)\n",
      "nonzero params:  tensor(0.7580)\n",
      "0.8833333333333333\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.6818)\n",
      "nonzero params:  tensor(0.6450)\n",
      "0.8828\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.5686)\n",
      "nonzero params:  tensor(0.5644)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828666666666667\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.4662)\n",
      "nonzero params:  tensor(0.4829)\n",
      "0.8801333333333332\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.3686)\n",
      "nonzero params:  tensor(0.3888)\n",
      "0.8643333333333333\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.2699)\n",
      "nonzero params:  tensor(0.2820)\n",
      "0.8475666666666667\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.1818)\n",
      "nonzero params:  tensor(0.1916)\n",
      "0.8197666666666666\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.0927)\n",
      "nonzero params:  tensor(0.1011)\n",
      "0.6751666666666667\n",
      "Number of net: 0 tensor(94562.7266) tensor(84650.3438) tensor(9912.3828)\n",
      "Number of net: 0 tensor(72583.6250) tensor(62676.3594) tensor(9907.2686)\n",
      "Number of net: 1 tensor(95670.0703) tensor(85830.9141) tensor(9839.1543)\n",
      "Number of net: 1 tensor(72797.8750) tensor(63099.2539) tensor(9698.6211)\n",
      "Number of net: 2 tensor(91242.3516) tensor(81398.3594) tensor(9843.9902)\n",
      "Number of net: 2 tensor(85125.8203) tensor(75429.0625) tensor(9696.7588)\n",
      "end of epoch:  0\n",
      "Number of net: 0\n",
      "tensor(19819.5781, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19320.5039, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19291.8535, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(51357.0391) tensor(41447.6758) tensor(9909.3652)\n",
      "Number of net: 0 tensor(55392.6367) tensor(45482.1406) tensor(9910.4951)\n",
      "Number of net: 1 tensor(41182.4062) tensor(31583.9336) tensor(9598.4717)\n",
      "Number of net: 1 tensor(59075.4062) tensor(49514.1523) tensor(9561.2549)\n",
      "Number of net: 2 tensor(49530.4883) tensor(40033.8555) tensor(9496.6318)\n",
      "Number of net: 2 tensor(55593.4023) tensor(46188.1289) tensor(9405.2725)\n",
      "end of epoch:  1\n",
      "Number of net: 0\n",
      "tensor(19824.0059, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19096.9688, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18771.7891, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(43946.5352) tensor(34035.4531) tensor(9911.0811)\n",
      "Number of net: 0 tensor(40558.5352) tensor(30646.8418) tensor(9911.6943)\n",
      "Number of net: 1 tensor(33272.7617) tensor(23757.6699) tensor(9515.0918)\n",
      "Number of net: 1 tensor(43419.9531) tensor(33913.8516) tensor(9506.1035)\n",
      "Number of net: 2 tensor(44748.3281) tensor(35428.4609) tensor(9319.8672)\n",
      "Number of net: 2 tensor(57932.4258) tensor(48673.4023) tensor(9259.0225)\n",
      "end of epoch:  2\n",
      "Number of net: 0\n",
      "tensor(19824.5371, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19011.3906, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18488.4922, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(36806.7891) tensor(26896.2832) tensor(9910.5059)\n",
      "Number of net: 0 tensor(39765.1836) tensor(29856.4551) tensor(9908.7295)\n",
      "Number of net: 1 tensor(38472.2578) tensor(28969.4746) tensor(9502.7812)\n",
      "Number of net: 1 tensor(37501.2812) tensor(28000.9082) tensor(9500.3711)\n",
      "Number of net: 2 tensor(39976.2148) tensor(30778.1367) tensor(9198.0791)\n",
      "Number of net: 2 tensor(35418.8750) tensor(26261.9512) tensor(9156.9219)\n",
      "end of epoch:  3\n",
      "Number of net: 0\n",
      "tensor(19815.7812, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18999.8652, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18286.6797, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(41523.8867) tensor(31618.5234) tensor(9905.3623)\n",
      "Number of net: 0 tensor(38504.2656) tensor(28600.2285) tensor(9904.0391)\n",
      "Number of net: 1 tensor(34467.8906) tensor(24971.8125) tensor(9496.0781)\n",
      "Number of net: 1 tensor(31710.9805) tensor(22218.0137) tensor(9492.9668)\n",
      "Number of net: 2 tensor(43502.6172) tensor(34396.9141) tensor(9105.7021)\n",
      "Number of net: 2 tensor(39169.3047) tensor(30093.9238) tensor(9075.3799)\n",
      "end of epoch:  4\n",
      "Number of net: 0\n",
      "tensor(19808.5996, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18983.8301, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18127.7305, grad_fn=<AddBackward0>)\n",
      "[array([[0.06342486, 0.07628375, 1.2487539 , ..., 0.82246375, 2.3772674 ,\n",
      "        0.0402943 ],\n",
      "       [1.7564574 , 0.12763135, 1.8655651 , ..., 0.04759884, 0.16593118,\n",
      "        0.13944986],\n",
      "       [0.52848226, 0.4907978 , 0.00414096, ..., 0.94752353, 2.600468  ,\n",
      "        4.1385417 ],\n",
      "       ...,\n",
      "       [2.1476183 , 0.7822392 , 1.3825169 , ..., 0.17955893, 1.1230768 ,\n",
      "        2.4273553 ],\n",
      "       [0.0426634 , 0.8985828 , 0.20939021, ..., 4.0871625 , 0.37495884,\n",
      "        0.3649704 ],\n",
      "       [1.1065468 , 0.1300537 , 0.17162287, ..., 0.17892508, 0.47624084,\n",
      "        1.3347301 ]], dtype=float32), array([[7.1391904e-01, 7.1161252e-04, 2.8594315e-01, ..., 4.1081548e-01,\n",
      "        2.7371140e+00, 4.1667750e-01],\n",
      "       [1.4480107e+00, 1.1259849e-03, 1.4463183e+00, ..., 1.9374166e+00,\n",
      "        1.0172172e-01, 5.0176699e-02],\n",
      "       [7.2914161e-02, 1.1634819e-02, 1.5398765e+00, ..., 1.7412660e+00,\n",
      "        1.0922872e+00, 6.6862798e-01],\n",
      "       ...,\n",
      "       [6.8011278e-01, 2.1511316e-02, 1.8359030e-02, ..., 2.6163673e+00,\n",
      "        2.7491124e+00, 3.2019789e+00],\n",
      "       [7.9420947e-02, 1.2300110e-02, 1.2836546e+00, ..., 1.7889326e-02,\n",
      "        1.1710181e+00, 6.2209225e-01],\n",
      "       [3.6606207e-01, 1.6548395e-02, 6.4676013e-03, ..., 2.6294252e-02,\n",
      "        4.2478658e-02, 1.2981930e+00]], dtype=float32), array([[3.7215190e+00, 3.5811201e-02, 8.4609631e-04, ..., 1.8535849e-01,\n",
      "        1.4607489e+00, 8.7088001e-01],\n",
      "       [1.6845436e+00, 1.7140230e-02, 3.8065821e-02, ..., 1.2503790e-03,\n",
      "        4.6134681e-01, 2.1690524e+00],\n",
      "       [7.1635956e-01, 3.8863733e-02, 9.4199531e-02, ..., 5.2973542e-02,\n",
      "        4.7860092e-01, 5.0480247e-01],\n",
      "       ...,\n",
      "       [8.2759745e-02, 2.0403761e-02, 3.4047100e-01, ..., 2.0844857e-03,\n",
      "        1.9463281e-01, 7.8562021e-01],\n",
      "       [1.5448916e-01, 2.7494621e-02, 7.1631908e-02, ..., 1.2650634e-01,\n",
      "        2.4867418e+00, 1.3225518e+00],\n",
      "       [1.8545500e+00, 3.6436968e-02, 2.7036655e-01, ..., 1.9259174e-01,\n",
      "        4.4512549e-01, 7.3073041e-01]], dtype=float32)]\n",
      "[array([[0.06342486, 0.07628375, 1.2487539 , ..., 0.82246375, 2.3772674 ,\n",
      "        0.0402943 ],\n",
      "       [1.7564574 , 0.12763135, 1.8655651 , ..., 0.04759884, 0.16593118,\n",
      "        0.13944986],\n",
      "       [0.52848226, 0.4907978 , 0.00414096, ..., 0.94752353, 2.600468  ,\n",
      "        4.1385417 ],\n",
      "       ...,\n",
      "       [2.1476183 , 0.7822392 , 1.3825169 , ..., 0.17955893, 1.1230768 ,\n",
      "        2.4273553 ],\n",
      "       [0.0426634 , 0.8985828 , 0.20939021, ..., 4.0871625 , 0.37495884,\n",
      "        0.3649704 ],\n",
      "       [1.1065468 , 0.1300537 , 0.17162287, ..., 0.17892508, 0.47624084,\n",
      "        1.3347301 ]], dtype=float32), array([[7.1391904e-01, 7.1161252e-04, 2.8594315e-01, ..., 4.1081548e-01,\n",
      "        2.7371140e+00, 4.1667750e-01],\n",
      "       [1.4480107e+00, 1.1259849e-03, 1.4463183e+00, ..., 1.9374166e+00,\n",
      "        1.0172172e-01, 5.0176699e-02],\n",
      "       [7.2914161e-02, 1.1634819e-02, 1.5398765e+00, ..., 1.7412660e+00,\n",
      "        1.0922872e+00, 6.6862798e-01],\n",
      "       ...,\n",
      "       [6.8011278e-01, 2.1511316e-02, 1.8359030e-02, ..., 2.6163673e+00,\n",
      "        2.7491124e+00, 3.2019789e+00],\n",
      "       [7.9420947e-02, 1.2300110e-02, 1.2836546e+00, ..., 1.7889326e-02,\n",
      "        1.1710181e+00, 6.2209225e-01],\n",
      "       [3.6606207e-01, 1.6548395e-02, 6.4676013e-03, ..., 2.6294252e-02,\n",
      "        4.2478658e-02, 1.2981930e+00]], dtype=float32), array([[3.7215190e+00, 3.5811201e-02, 8.4609631e-04, ..., 1.8535849e-01,\n",
      "        1.4607489e+00, 8.7088001e-01],\n",
      "       [1.6845436e+00, 1.7140230e-02, 3.8065821e-02, ..., 1.2503790e-03,\n",
      "        4.6134681e-01, 2.1690524e+00],\n",
      "       [7.1635956e-01, 3.8863733e-02, 9.4199531e-02, ..., 5.2973542e-02,\n",
      "        4.7860092e-01, 5.0480247e-01],\n",
      "       ...,\n",
      "       [8.2759745e-02, 2.0403761e-02, 3.4047100e-01, ..., 2.0844857e-03,\n",
      "        1.9463281e-01, 7.8562021e-01],\n",
      "       [1.5448916e-01, 2.7494621e-02, 7.1631908e-02, ..., 1.2650634e-01,\n",
      "        2.4867418e+00, 1.3225518e+00],\n",
      "       [1.8545500e+00, 3.6436968e-02, 2.7036655e-01, ..., 1.9259174e-01,\n",
      "        4.4512549e-01, 7.3073041e-01]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(1.)\n",
      "nonzero params:  tensor(0.9996)\n",
      "0.8815\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.8614)\n",
      "nonzero params:  tensor(0.7829)\n",
      "0.8804\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.7321)\n",
      "nonzero params:  tensor(0.6300)\n",
      "0.8784\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.6247)\n",
      "nonzero params:  tensor(0.5268)\n",
      "0.8754666666666667\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.5116)\n",
      "nonzero params:  tensor(0.4408)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747666666666666\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.4158)\n",
      "nonzero params:  tensor(0.3689)\n",
      "0.8630666666666666\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.3376)\n",
      "nonzero params:  tensor(0.3011)\n",
      "0.8523999999999999\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.2654)\n",
      "nonzero params:  tensor(0.2307)\n",
      "0.8442666666666666\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.1898)\n",
      "nonzero params:  tensor(0.1593)\n",
      "0.8102999999999999\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.0969)\n",
      "nonzero params:  tensor(0.0761)\n",
      "0.5900666666666667\n",
      "Number of net: 0 tensor(92733.0859) tensor(73026.3047) tensor(19706.7793)\n",
      "Number of net: 0 tensor(82896.8438) tensor(63357.9766) tensor(19538.8691)\n",
      "Number of net: 1 tensor(113672.2969) tensor(94000.2969) tensor(19672.0020)\n",
      "Number of net: 1 tensor(94906.9453) tensor(75467.4375) tensor(19439.5098)\n",
      "Number of net: 2 tensor(108685.8047) tensor(88902.7109) tensor(19783.0918)\n",
      "Number of net: 2 tensor(79050.4453) tensor(59302.2070) tensor(19748.2363)\n",
      "end of epoch:  0\n",
      "Number of net: 0\n",
      "tensor(19510.6172, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19411.0059, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19747.6719, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(63733.5234) tensor(44312.0586) tensor(19421.4648)\n",
      "Number of net: 0 tensor(61754.4609) tensor(42416.8008) tensor(19337.6621)\n",
      "Number of net: 1 tensor(94560.0703) tensor(75165.3359) tensor(19394.7324)\n",
      "Number of net: 1 tensor(58531.3125) tensor(39149.0977) tensor(19382.2129)\n",
      "Number of net: 2 tensor(75811.7344) tensor(56079.3633) tensor(19732.3711)\n",
      "Number of net: 2 tensor(55966.1250) tensor(36247.2539) tensor(19718.8691)\n",
      "end of epoch:  1\n",
      "Number of net: 0\n",
      "tensor(19306.9531, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19378.8906, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19716.0547, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(54506.2188) tensor(35290.7617) tensor(19215.4551)\n",
      "Number of net: 0 tensor(49853.5586) tensor(30659.1934) tensor(19194.3652)\n",
      "Number of net: 1 tensor(62228.2734) tensor(42869.5781) tensor(19358.6934)\n",
      "Number of net: 1 tensor(53749.2852) tensor(34409.2617) tensor(19340.0234)\n",
      "Number of net: 2 tensor(46692.9141) tensor(26995.5938) tensor(19697.3223)\n",
      "Number of net: 2 tensor(47503.5391) tensor(27822.8477) tensor(19680.6895)\n",
      "end of epoch:  2\n",
      "Number of net: 0\n",
      "tensor(19189.7969, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19333.1621, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19675.5371, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(51516.9453) tensor(32350.2344) tensor(19166.7109)\n",
      "Number of net: 0 tensor(53176.5000) tensor(34029.4414) tensor(19147.0605)\n",
      "Number of net: 1 tensor(44407.0938) tensor(25099.2344) tensor(19307.8613)\n",
      "Number of net: 1 tensor(64850.1562) tensor(45565.1328) tensor(19285.0254)\n",
      "Number of net: 2 tensor(53899.0781) tensor(34243.7930) tensor(19655.2852)\n",
      "Number of net: 2 tensor(45772.9141) tensor(26138.7773) tensor(19634.1348)\n",
      "end of epoch:  3\n",
      "Number of net: 0\n",
      "tensor(19140.2637, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19277.1445, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19625.5312, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(52206.4531) tensor(33088.3125) tensor(19118.1426)\n",
      "Number of net: 0 tensor(41864.8008) tensor(22769.0996) tensor(19095.7012)\n",
      "Number of net: 1 tensor(42117.0312) tensor(22868.3633) tensor(19248.6660)\n",
      "Number of net: 1 tensor(61718.3945) tensor(42496.7617) tensor(19221.6328)\n",
      "Number of net: 2 tensor(48295.4180) tensor(28693.3047) tensor(19602.1133)\n",
      "Number of net: 2 tensor(47807.3281) tensor(28225.3535) tensor(19581.9746)\n",
      "end of epoch:  4\n",
      "Number of net: 0\n",
      "tensor(19089.6191, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19214.6055, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19576.8008, grad_fn=<AddBackward0>)\n",
      "[array([[7.9992108e-02, 1.4912332e+00, 1.9166169e-01, ..., 1.5199856e-03,\n",
      "        2.3831363e+00, 1.2018117e+00],\n",
      "       [9.2290258e-01, 1.2810478e+00, 3.3153030e-01, ..., 1.2508782e-02,\n",
      "        1.8457999e+00, 4.7940484e-01],\n",
      "       [1.1746514e-01, 3.2287376e+00, 2.1615784e+00, ..., 1.3475990e-01,\n",
      "        1.0335996e+00, 2.0630379e-01],\n",
      "       ...,\n",
      "       [2.4006590e-02, 1.4102067e+00, 1.9577034e+00, ..., 1.3658049e+00,\n",
      "        6.0998517e-01, 7.9344034e-01],\n",
      "       [3.0921806e-02, 7.2232492e-02, 4.1235480e-01, ..., 5.9749585e-01,\n",
      "        3.4011052e+00, 2.5238404e+00],\n",
      "       [1.6471344e-01, 2.7360508e-01, 4.9814707e-01, ..., 2.5464371e-01,\n",
      "        4.9230400e-01, 1.4936763e-03]], dtype=float32), array([[3.0199441e-01, 7.8972626e-01, 3.0111054e-01, ..., 5.6951147e-01,\n",
      "        8.7606770e-01, 2.1630340e+00],\n",
      "       [1.6023562e+00, 8.7952510e-02, 2.3986969e-02, ..., 2.4140803e-02,\n",
      "        5.4675031e-01, 1.1037207e-03],\n",
      "       [2.8166527e-02, 5.7851267e-01, 4.1073770e-05, ..., 2.0906637e+00,\n",
      "        1.4076647e+00, 1.1308142e+00],\n",
      "       ...,\n",
      "       [4.7463369e-01, 1.0869837e-01, 1.0157675e-01, ..., 3.7211075e-01,\n",
      "        5.1636076e-01, 9.0994304e-01],\n",
      "       [1.8503026e+00, 6.4482987e-01, 9.8371506e-01, ..., 2.1778955e+00,\n",
      "        2.3002395e-01, 3.6856061e-01],\n",
      "       [1.7299218e+00, 1.2291600e-01, 3.2249644e+00, ..., 3.5649341e-01,\n",
      "        4.2305300e-01, 3.5059623e-02]], dtype=float32), array([[1.3517171e+00, 3.0571107e-02, 8.0993259e-01, ..., 2.0219767e+00,\n",
      "        5.6179148e-01, 1.6264063e+00],\n",
      "       [5.1862904e-04, 1.5026397e+00, 5.9316558e-01, ..., 1.1747074e+00,\n",
      "        1.2590647e-01, 8.9148426e-01],\n",
      "       [4.5304841e-01, 2.1921570e+00, 6.2704456e-01, ..., 2.0646441e+00,\n",
      "        6.0753751e-01, 1.5677316e-01],\n",
      "       ...,\n",
      "       [1.5628164e+00, 6.9247502e-01, 1.1811661e+00, ..., 3.4673440e+00,\n",
      "        6.3344258e-01, 3.1380143e-04],\n",
      "       [2.3634470e-01, 3.4857142e+00, 2.0713732e+00, ..., 1.5213557e+00,\n",
      "        1.3969292e-01, 4.0575933e-01],\n",
      "       [1.7808115e-02, 3.3520310e+00, 4.3149769e-01, ..., 2.1181071e+00,\n",
      "        7.6945476e-02, 3.9178371e-02]], dtype=float32)]\n",
      "[array([[7.9992108e-02, 1.4912332e+00, 1.9166169e-01, ..., 1.5199856e-03,\n",
      "        2.3831363e+00, 1.2018117e+00],\n",
      "       [9.2290258e-01, 1.2810478e+00, 3.3153030e-01, ..., 1.2508782e-02,\n",
      "        1.8457999e+00, 4.7940484e-01],\n",
      "       [1.1746514e-01, 3.2287376e+00, 2.1615784e+00, ..., 1.3475990e-01,\n",
      "        1.0335996e+00, 2.0630379e-01],\n",
      "       ...,\n",
      "       [2.4006590e-02, 1.4102067e+00, 1.9577034e+00, ..., 1.3658049e+00,\n",
      "        6.0998517e-01, 7.9344034e-01],\n",
      "       [3.0921806e-02, 7.2232492e-02, 4.1235480e-01, ..., 5.9749585e-01,\n",
      "        3.4011052e+00, 2.5238404e+00],\n",
      "       [1.6471344e-01, 2.7360508e-01, 4.9814707e-01, ..., 2.5464371e-01,\n",
      "        4.9230400e-01, 1.4936763e-03]], dtype=float32), array([[3.0199441e-01, 7.8972626e-01, 3.0111054e-01, ..., 5.6951147e-01,\n",
      "        8.7606770e-01, 2.1630340e+00],\n",
      "       [1.6023562e+00, 8.7952510e-02, 2.3986969e-02, ..., 2.4140803e-02,\n",
      "        5.4675031e-01, 1.1037207e-03],\n",
      "       [2.8166527e-02, 5.7851267e-01, 4.1073770e-05, ..., 2.0906637e+00,\n",
      "        1.4076647e+00, 1.1308142e+00],\n",
      "       ...,\n",
      "       [4.7463369e-01, 1.0869837e-01, 1.0157675e-01, ..., 3.7211075e-01,\n",
      "        5.1636076e-01, 9.0994304e-01],\n",
      "       [1.8503026e+00, 6.4482987e-01, 9.8371506e-01, ..., 2.1778955e+00,\n",
      "        2.3002395e-01, 3.6856061e-01],\n",
      "       [1.7299218e+00, 1.2291600e-01, 3.2249644e+00, ..., 3.5649341e-01,\n",
      "        4.2305300e-01, 3.5059623e-02]], dtype=float32), array([[1.3517171e+00, 3.0571107e-02, 8.0993259e-01, ..., 2.0219767e+00,\n",
      "        5.6179148e-01, 1.6264063e+00],\n",
      "       [5.1862904e-04, 1.5026397e+00, 5.9316558e-01, ..., 1.1747074e+00,\n",
      "        1.2590647e-01, 8.9148426e-01],\n",
      "       [4.5304841e-01, 2.1921570e+00, 6.2704456e-01, ..., 2.0646441e+00,\n",
      "        6.0753751e-01, 1.5677316e-01],\n",
      "       ...,\n",
      "       [1.5628164e+00, 6.9247502e-01, 1.1811661e+00, ..., 3.4673440e+00,\n",
      "        6.3344258e-01, 3.1380143e-04],\n",
      "       [2.3634470e-01, 3.4857142e+00, 2.0713732e+00, ..., 1.5213557e+00,\n",
      "        1.3969292e-01, 4.0575933e-01],\n",
      "       [1.7808115e-02, 3.3520310e+00, 4.3149769e-01, ..., 2.1181071e+00,\n",
      "        7.6945476e-02, 3.9178371e-02]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(1.)\n",
      "0.8879333333333334\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.9158)\n",
      "nonzero params:  tensor(0.9361)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8872666666666668\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.8185)\n",
      "nonzero params:  tensor(0.8636)\n",
      "0.8838666666666667\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.7033)\n",
      "nonzero params:  tensor(0.7686)\n",
      "0.8784000000000001\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.5949)\n",
      "nonzero params:  tensor(0.6684)\n",
      "0.8725\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.4997)\n",
      "nonzero params:  tensor(0.5677)\n",
      "0.8553000000000001\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.3894)\n",
      "nonzero params:  tensor(0.4529)\n",
      "0.8166333333333333\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.2950)\n",
      "nonzero params:  tensor(0.3390)\n",
      "0.8010999999999999\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.1978)\n",
      "nonzero params:  tensor(0.2249)\n",
      "0.7883999999999999\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.1050)\n",
      "nonzero params:  tensor(0.1115)\n",
      "0.6669666666666666\n",
      "Number of net: 0 tensor(185762.3750) tensor(87826.9062) tensor(97935.4766)\n",
      "Number of net: 0 tensor(158505.5469) tensor(61516.1719) tensor(96989.3750)\n",
      "Number of net: 1 tensor(190460.9688) tensor(92170.3984) tensor(98290.5781)\n",
      "Number of net: 1 tensor(158424.8281) tensor(60752.8086) tensor(97672.0234)\n",
      "Number of net: 2 tensor(183649.9375) tensor(85517.2031) tensor(98132.7422)\n",
      "Number of net: 2 tensor(194418.6094) tensor(96785.6797) tensor(97632.9297)\n",
      "end of epoch:  0\n",
      "Number of net: 0\n",
      "tensor(19338.0195, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19496.5977, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19503.1855, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(134889.9844) tensor(38876.0664) tensor(96013.9219)\n",
      "Number of net: 0 tensor(133548.4062) tensor(38144.1523) tensor(95404.2578)\n",
      "Number of net: 1 tensor(132727.6094) tensor(35713.6328) tensor(97013.9766)\n",
      "Number of net: 1 tensor(134475.) tensor(37942.4805) tensor(96532.5156)\n",
      "Number of net: 2 tensor(140518.3750) tensor(43431.3125) tensor(97087.0625)\n",
      "Number of net: 2 tensor(132836.1562) tensor(36174.4766) tensor(96661.6875)\n",
      "end of epoch:  1\n",
      "Number of net: 0\n",
      "tensor(19037.2168, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19266.6152, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19301.9941, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(128682.0938) tensor(34152.3242) tensor(94529.7656)\n",
      "Number of net: 0 tensor(142712.1094) tensor(48785.7383) tensor(93926.3750)\n",
      "Number of net: 1 tensor(131632.3750) tensor(35843.6523) tensor(95788.7188)\n",
      "Number of net: 1 tensor(138102.7500) tensor(42886.1953) tensor(95216.5469)\n",
      "Number of net: 2 tensor(131053.6719) tensor(35051.0820) tensor(96002.5938)\n",
      "Number of net: 2 tensor(123351.6719) tensor(27870.0762) tensor(95481.5938)\n",
      "end of epoch:  2\n",
      "Number of net: 0\n",
      "tensor(18741.7070, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19004.3633, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19060.0527, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(116940.7812) tensor(23908.4492) tensor(93032.3281)\n",
      "Number of net: 0 tensor(119842.7578) tensor(27454.4707) tensor(92388.2891)\n",
      "Number of net: 1 tensor(117788.0078) tensor(23388.5215) tensor(94399.4844)\n",
      "Number of net: 1 tensor(113057.9531) tensor(19235.0801) tensor(93822.8750)\n",
      "Number of net: 2 tensor(134173.0156) tensor(39395.5586) tensor(94777.4609)\n",
      "Number of net: 2 tensor(127658.2812) tensor(33404.5117) tensor(94253.7656)\n",
      "end of epoch:  3\n",
      "Number of net: 0\n",
      "tensor(18431.2754, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18720.0449, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18811.4434, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(112867.1953) tensor(21385.4590) tensor(91481.7344)\n",
      "Number of net: 0 tensor(118591.0156) tensor(27754.7031) tensor(90836.3125)\n",
      "Number of net: 1 tensor(114207.2578) tensor(21253.0684) tensor(92954.1875)\n",
      "Number of net: 1 tensor(111657.7656) tensor(19291.9180) tensor(92365.8516)\n",
      "Number of net: 2 tensor(117523.0156) tensor(24022.5020) tensor(93500.5156)\n",
      "Number of net: 2 tensor(120372.9531) tensor(27403.2539) tensor(92969.6953)\n",
      "end of epoch:  4\n",
      "Number of net: 0\n",
      "tensor(18115.7031, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18428.9922, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18552.7773, grad_fn=<AddBackward0>)\n",
      "[array([[9.69283208e-02, 8.32629323e-01, 7.26654530e-01, ...,\n",
      "        7.25388646e-01, 4.81770962e-01, 1.57075883e-05],\n",
      "       [1.07218668e-01, 1.26977876e-01, 1.32836330e+00, ...,\n",
      "        4.05525744e-01, 2.46983975e-01, 1.49890780e-02],\n",
      "       [3.75652537e-02, 4.56066638e-01, 5.95176697e-01, ...,\n",
      "        3.57721955e-01, 1.16970465e-01, 1.05324872e-01],\n",
      "       ...,\n",
      "       [1.08221611e-02, 2.12358534e-01, 6.27179071e-03, ...,\n",
      "        2.87994072e-02, 5.18908501e-02, 1.15027785e-01],\n",
      "       [7.86596239e-02, 1.99878657e+00, 2.52724797e-01, ...,\n",
      "        4.83234704e-01, 2.05147791e+00, 2.78327484e-02],\n",
      "       [7.47665048e-01, 1.78144348e+00, 3.01766425e-01, ...,\n",
      "        3.31188701e-02, 1.12126660e+00, 5.08763418e-02]], dtype=float32), array([[0.5148338 , 0.00511462, 0.95054656, ..., 0.57593167, 0.17135023,\n",
      "        0.11506429],\n",
      "       [2.1887164 , 1.648704  , 0.57476246, ..., 0.38071823, 0.9396517 ,\n",
      "        0.08563188],\n",
      "       [2.7068567 , 1.3943055 , 0.05233739, ..., 0.21499528, 0.27399012,\n",
      "        0.02837914],\n",
      "       ...,\n",
      "       [0.69199294, 0.05755774, 0.0501011 , ..., 0.11882225, 0.61362165,\n",
      "        0.02126223],\n",
      "       [0.625435  , 0.4544198 , 0.96146023, ..., 2.3607845 , 1.0324473 ,\n",
      "        0.09201394],\n",
      "       [1.3836819 , 1.3768436 , 0.03710287, ..., 0.46368   , 0.49605998,\n",
      "        0.02552255]], dtype=float32), array([[6.2935971e-02, 2.3781881e+00, 8.9670157e-01, ..., 2.1610156e-02,\n",
      "        3.7419191e-01, 1.1592073e+00],\n",
      "       [2.8974608e-02, 3.9934811e-01, 1.4934763e+00, ..., 1.9630028e-01,\n",
      "        3.2772399e-02, 2.1075873e+00],\n",
      "       [2.9512062e-03, 8.8513811e-04, 2.2078685e-01, ..., 1.8138465e+00,\n",
      "        1.2964085e+00, 2.2951562e+00],\n",
      "       ...,\n",
      "       [4.2137038e-02, 3.8496995e-01, 5.3568166e-01, ..., 1.5041652e-02,\n",
      "        7.7592927e-01, 1.6886116e+00],\n",
      "       [1.3358202e-02, 2.7402475e+00, 1.5055580e-01, ..., 1.0691011e+00,\n",
      "        9.4606763e-01, 1.3564991e-02],\n",
      "       [3.9145622e-02, 9.9828281e-02, 4.0818432e-01, ..., 1.0462626e+00,\n",
      "        3.9554575e-01, 7.7316993e-01]], dtype=float32)]\n",
      "[array([[9.69283208e-02, 8.32629323e-01, 7.26654530e-01, ...,\n",
      "        7.25388646e-01, 4.81770962e-01, 1.57075883e-05],\n",
      "       [1.07218668e-01, 1.26977876e-01, 1.32836330e+00, ...,\n",
      "        4.05525744e-01, 2.46983975e-01, 1.49890780e-02],\n",
      "       [3.75652537e-02, 4.56066638e-01, 5.95176697e-01, ...,\n",
      "        3.57721955e-01, 1.16970465e-01, 1.05324872e-01],\n",
      "       ...,\n",
      "       [1.08221611e-02, 2.12358534e-01, 6.27179071e-03, ...,\n",
      "        2.87994072e-02, 5.18908501e-02, 1.15027785e-01],\n",
      "       [7.86596239e-02, 1.99878657e+00, 2.52724797e-01, ...,\n",
      "        4.83234704e-01, 2.05147791e+00, 2.78327484e-02],\n",
      "       [7.47665048e-01, 1.78144348e+00, 3.01766425e-01, ...,\n",
      "        3.31188701e-02, 1.12126660e+00, 5.08763418e-02]], dtype=float32), array([[0.5148338 , 0.00511462, 0.95054656, ..., 0.57593167, 0.17135023,\n",
      "        0.11506429],\n",
      "       [2.1887164 , 1.648704  , 0.57476246, ..., 0.38071823, 0.9396517 ,\n",
      "        0.08563188],\n",
      "       [2.7068567 , 1.3943055 , 0.05233739, ..., 0.21499528, 0.27399012,\n",
      "        0.02837914],\n",
      "       ...,\n",
      "       [0.69199294, 0.05755774, 0.0501011 , ..., 0.11882225, 0.61362165,\n",
      "        0.02126223],\n",
      "       [0.625435  , 0.4544198 , 0.96146023, ..., 2.3607845 , 1.0324473 ,\n",
      "        0.09201394],\n",
      "       [1.3836819 , 1.3768436 , 0.03710287, ..., 0.46368   , 0.49605998,\n",
      "        0.02552255]], dtype=float32), array([[6.2935971e-02, 2.3781881e+00, 8.9670157e-01, ..., 2.1610156e-02,\n",
      "        3.7419191e-01, 1.1592073e+00],\n",
      "       [2.8974608e-02, 3.9934811e-01, 1.4934763e+00, ..., 1.9630028e-01,\n",
      "        3.2772399e-02, 2.1075873e+00],\n",
      "       [2.9512062e-03, 8.8513811e-04, 2.2078685e-01, ..., 1.8138465e+00,\n",
      "        1.2964085e+00, 2.2951562e+00],\n",
      "       ...,\n",
      "       [4.2137038e-02, 3.8496995e-01, 5.3568166e-01, ..., 1.5041652e-02,\n",
      "        7.7592927e-01, 1.6886116e+00],\n",
      "       [1.3358202e-02, 2.7402475e+00, 1.5055580e-01, ..., 1.0691011e+00,\n",
      "        9.4606763e-01, 1.3564991e-02],\n",
      "       [3.9145622e-02, 9.9828281e-02, 4.0818432e-01, ..., 1.0462626e+00,\n",
      "        3.9554575e-01, 7.7316993e-01]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(1.)\n",
      "nonzero params:  tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8873666666666667\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.9182)\n",
      "nonzero params:  tensor(0.9094)\n",
      "0.8876666666666666\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.8268)\n",
      "nonzero params:  tensor(0.7960)\n",
      "0.8855666666666666\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.7380)\n",
      "nonzero params:  tensor(0.7060)\n",
      "0.8807666666666667\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.6501)\n",
      "nonzero params:  tensor(0.6273)\n",
      "0.8718666666666667\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.5505)\n",
      "nonzero params:  tensor(0.5284)\n",
      "0.8608333333333333\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.4499)\n",
      "nonzero params:  tensor(0.4305)\n",
      "0.8485999999999999\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.3333)\n",
      "nonzero params:  tensor(0.3241)\n",
      "0.8172333333333333\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.2191)\n",
      "nonzero params:  tensor(0.2082)\n",
      "0.7719999999999999\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.1009)\n",
      "nonzero params:  tensor(0.0936)\n",
      "0.7282666666666667\n",
      "Number of net: 0 tensor(330969.0625) tensor(135062.5781) tensor(195906.4688)\n",
      "Number of net: 0 tensor(248327.6250) tensor(54030.9883) tensor(194296.6406)\n",
      "Number of net: 1 tensor(324985.4062) tensor(129038.2422) tensor(195947.1562)\n",
      "Number of net: 1 tensor(247965.2188) tensor(54094.8398) tensor(193870.3750)\n",
      "Number of net: 2 tensor(290232.8125) tensor(93285.9375) tensor(196946.8906)\n",
      "Number of net: 2 tensor(243315.7812) tensor(47757.4297) tensor(195558.3594)\n",
      "end of epoch:  0\n",
      "Number of net: 0\n",
      "tensor(19383.3887, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(19316.3477, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19506.2383, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(236118.1562) tensor(43872.6328) tensor(192245.5312)\n",
      "Number of net: 0 tensor(242865.0938) tensor(52306.9414) tensor(190558.1562)\n",
      "Number of net: 1 tensor(228183.8281) tensor(37026.6992) tensor(191157.1250)\n",
      "Number of net: 1 tensor(230974.8750) tensor(41740.8672) tensor(189234.)\n",
      "Number of net: 2 tensor(234294.1562) tensor(40807.0664) tensor(193487.0938)\n",
      "Number of net: 2 tensor(223489.) tensor(31687.4746) tensor(191801.5312)\n",
      "end of epoch:  1\n",
      "Number of net: 0\n",
      "tensor(18987.3594, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18854.3516, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(19116.2617, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(221031.7500) tensor(33016.5195) tensor(188015.2344)\n",
      "Number of net: 0 tensor(218149.5781) tensor(32107.5371) tensor(186042.0469)\n",
      "Number of net: 1 tensor(230817.9062) tensor(44374.4766) tensor(186443.4219)\n",
      "Number of net: 1 tensor(217700.9062) tensor(33255.8516) tensor(184445.0625)\n",
      "Number of net: 2 tensor(225755.2031) tensor(36273.2617) tensor(189481.9375)\n",
      "Number of net: 2 tensor(223321.2969) tensor(35493.0039) tensor(187828.2969)\n",
      "end of epoch:  2\n",
      "Number of net: 0\n",
      "tensor(18533.4551, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18376.2383, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18722.1602, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(204841.1562) tensor(21320.0566) tensor(183521.0938)\n",
      "Number of net: 0 tensor(215567.1250) tensor(34001.1289) tensor(181566.)\n",
      "Number of net: 1 tensor(221411.2812) tensor(39562.6758) tensor(181848.6094)\n",
      "Number of net: 1 tensor(210776.6094) tensor(30965.8320) tensor(179810.7812)\n",
      "Number of net: 2 tensor(224290.8906) tensor(38873.9531) tensor(185416.9375)\n",
      "Number of net: 2 tensor(217327.5156) tensor(33747.8477) tensor(183579.6719)\n",
      "end of epoch:  3\n",
      "Number of net: 0\n",
      "tensor(18089.9082, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(17904.0957, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18297.1074, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(213518.1406) tensor(34535.7969) tensor(178982.3438)\n",
      "Number of net: 0 tensor(205572.0781) tensor(28463.3867) tensor(177108.6875)\n",
      "Number of net: 1 tensor(206323.6562) tensor(29325.7266) tensor(176997.9375)\n",
      "Number of net: 1 tensor(212101.3750) tensor(37030.0938) tensor(175071.2812)\n",
      "Number of net: 2 tensor(207975.4375) tensor(26752.9219) tensor(181222.5156)\n",
      "Number of net: 2 tensor(206705.7344) tensor(27417.3340) tensor(179288.4062)\n",
      "end of epoch:  4\n",
      "Number of net: 0\n",
      "tensor(17640.5977, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(17435.9062, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(17867.3398, grad_fn=<AddBackward0>)\n",
      "[array([[4.63242173e-01, 2.53402710e-01, 1.31239986e+00, ...,\n",
      "        2.08220474e-04, 2.12545896e+00, 3.08398128e-01],\n",
      "       [7.04134107e-01, 6.09378330e-02, 7.47306585e-01, ...,\n",
      "        4.18798298e-01, 2.12494228e-02, 1.46068823e+00],\n",
      "       [3.99414934e-02, 1.40094411e+00, 1.58697402e+00, ...,\n",
      "        4.62224372e-02, 5.02249179e-03, 2.37800926e-01],\n",
      "       ...,\n",
      "       [1.17772138e+00, 2.44098797e-01, 6.48593977e-02, ...,\n",
      "        9.73207057e-02, 1.42527118e-01, 1.98395181e+00],\n",
      "       [1.01273012e+00, 1.00695753e+00, 7.95790493e-01, ...,\n",
      "        3.94085385e-02, 1.37994528e+00, 1.24101035e-01],\n",
      "       [9.85335648e-01, 3.17305595e-01, 6.10472150e-02, ...,\n",
      "        1.81600172e-03, 4.65970561e-02, 1.18257415e+00]], dtype=float32), array([[1.11060508e-03, 1.13630556e-01, 1.36075065e-01, ...,\n",
      "        1.38889027e+00, 2.34910343e-02, 2.01036781e-01],\n",
      "       [3.21230385e-03, 1.96345900e-05, 2.12644672e+00, ...,\n",
      "        1.15336728e+00, 1.41044104e+00, 4.17100638e-01],\n",
      "       [3.61311395e-05, 3.78144413e-01, 7.58695185e-01, ...,\n",
      "        1.86299030e-02, 9.54096147e-04, 1.02495670e+00],\n",
      "       ...,\n",
      "       [2.14927434e-03, 4.08168554e-01, 3.61766636e-01, ...,\n",
      "        6.46743253e-02, 1.85811490e-01, 6.59194350e-01],\n",
      "       [1.83729250e-02, 1.64520312e-02, 1.52616858e+00, ...,\n",
      "        4.77201194e-01, 1.21692705e+00, 5.13496925e-04],\n",
      "       [1.14060203e-04, 2.71541685e-01, 1.46542168e+00, ...,\n",
      "        1.06882811e+00, 1.90128665e-02, 7.86022022e-02]], dtype=float32), array([[1.1617407e+00, 1.6014137e+00, 4.1117507e-01, ..., 3.6260399e-01,\n",
      "        1.6992995e+00, 3.6943364e-01],\n",
      "       [5.1639920e-01, 1.0298729e-02, 1.7902699e-01, ..., 7.3890454e-01,\n",
      "        1.0965999e+00, 1.3272160e+00],\n",
      "       [1.7367858e+00, 6.6277194e-01, 3.8587507e-02, ..., 3.5101002e-01,\n",
      "        7.7210099e-02, 5.5280596e-02],\n",
      "       ...,\n",
      "       [2.9159237e-02, 8.0338460e-01, 6.0416508e-02, ..., 1.0831029e+00,\n",
      "        1.8940941e+00, 8.6274522e-05],\n",
      "       [6.0194898e-01, 1.6110759e+00, 2.5832906e-02, ..., 5.1158007e-02,\n",
      "        9.2892116e-01, 9.3025458e-01],\n",
      "       [2.8752180e-02, 7.3158073e-01, 1.8179846e-01, ..., 1.5544546e+00,\n",
      "        1.3061280e-02, 1.2699796e-02]], dtype=float32)]\n",
      "[array([[4.63242173e-01, 2.53402710e-01, 1.31239986e+00, ...,\n",
      "        2.08220474e-04, 2.12545896e+00, 3.08398128e-01],\n",
      "       [7.04134107e-01, 6.09378330e-02, 7.47306585e-01, ...,\n",
      "        4.18798298e-01, 2.12494228e-02, 1.46068823e+00],\n",
      "       [3.99414934e-02, 1.40094411e+00, 1.58697402e+00, ...,\n",
      "        4.62224372e-02, 5.02249179e-03, 2.37800926e-01],\n",
      "       ...,\n",
      "       [1.17772138e+00, 2.44098797e-01, 6.48593977e-02, ...,\n",
      "        9.73207057e-02, 1.42527118e-01, 1.98395181e+00],\n",
      "       [1.01273012e+00, 1.00695753e+00, 7.95790493e-01, ...,\n",
      "        3.94085385e-02, 1.37994528e+00, 1.24101035e-01],\n",
      "       [9.85335648e-01, 3.17305595e-01, 6.10472150e-02, ...,\n",
      "        1.81600172e-03, 4.65970561e-02, 1.18257415e+00]], dtype=float32), array([[1.11060508e-03, 1.13630556e-01, 1.36075065e-01, ...,\n",
      "        1.38889027e+00, 2.34910343e-02, 2.01036781e-01],\n",
      "       [3.21230385e-03, 1.96345900e-05, 2.12644672e+00, ...,\n",
      "        1.15336728e+00, 1.41044104e+00, 4.17100638e-01],\n",
      "       [3.61311395e-05, 3.78144413e-01, 7.58695185e-01, ...,\n",
      "        1.86299030e-02, 9.54096147e-04, 1.02495670e+00],\n",
      "       ...,\n",
      "       [2.14927434e-03, 4.08168554e-01, 3.61766636e-01, ...,\n",
      "        6.46743253e-02, 1.85811490e-01, 6.59194350e-01],\n",
      "       [1.83729250e-02, 1.64520312e-02, 1.52616858e+00, ...,\n",
      "        4.77201194e-01, 1.21692705e+00, 5.13496925e-04],\n",
      "       [1.14060203e-04, 2.71541685e-01, 1.46542168e+00, ...,\n",
      "        1.06882811e+00, 1.90128665e-02, 7.86022022e-02]], dtype=float32), array([[1.1617407e+00, 1.6014137e+00, 4.1117507e-01, ..., 3.6260399e-01,\n",
      "        1.6992995e+00, 3.6943364e-01],\n",
      "       [5.1639920e-01, 1.0298729e-02, 1.7902699e-01, ..., 7.3890454e-01,\n",
      "        1.0965999e+00, 1.3272160e+00],\n",
      "       [1.7367858e+00, 6.6277194e-01, 3.8587507e-02, ..., 3.5101002e-01,\n",
      "        7.7210099e-02, 5.5280596e-02],\n",
      "       ...,\n",
      "       [2.9159237e-02, 8.0338460e-01, 6.0416508e-02, ..., 1.0831029e+00,\n",
      "        1.8940941e+00, 8.6274522e-05],\n",
      "       [6.0194898e-01, 1.6110759e+00, 2.5832906e-02, ..., 5.1158007e-02,\n",
      "        9.2892116e-01, 9.3025458e-01],\n",
      "       [2.8752180e-02, 7.3158073e-01, 1.8179846e-01, ..., 1.5544546e+00,\n",
      "        1.3061280e-02, 1.2699796e-02]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(0.9986)\n",
      "nonzero params:  tensor(0.9996)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.8866)\n",
      "nonzero params:  tensor(0.9247)\n",
      "0.8926333333333334\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.7973)\n",
      "nonzero params:  tensor(0.8398)\n",
      "0.8933666666666668\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.7085)\n",
      "nonzero params:  tensor(0.7543)\n",
      "0.8934666666666667\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.6133)\n",
      "nonzero params:  tensor(0.6691)\n",
      "0.8888666666666666\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.5066)\n",
      "nonzero params:  tensor(0.5665)\n",
      "0.8792999999999999\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.4003)\n",
      "nonzero params:  tensor(0.4489)\n",
      "0.8722666666666666\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.2901)\n",
      "nonzero params:  tensor(0.3244)\n",
      "0.8558333333333333\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.1814)\n",
      "nonzero params:  tensor(0.2017)\n",
      "0.8133666666666667\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.1005)\n",
      "nonzero params:  tensor(0.1004)\n",
      "0.7653666666666666\n",
      "Number of net: 0 tensor(2023761.3750) tensor(95206.6797) tensor(1928554.7500)\n",
      "Number of net: 0 tensor(1929182.3750) tensor(57773.9609) tensor(1871408.3750)\n",
      "Number of net: 1 tensor(2005628.6250) tensor(73972.3672) tensor(1931656.2500)\n",
      "Number of net: 1 tensor(1935148.1250) tensor(60450.2617) tensor(1874697.8750)\n",
      "Number of net: 2 tensor(2021822.5000) tensor(89555.5625) tensor(1932267.)\n",
      "Number of net: 2 tensor(1933117.8750) tensor(57923.4961) tensor(1875194.3750)\n",
      "end of epoch:  0\n",
      "Number of net: 0\n",
      "tensor(18508.1934, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(18542.4238, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(18548.9824, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(1848192.7500) tensor(52575.8125) tensor(1795617.)\n",
      "Number of net: 0 tensor(1806228.8750) tensor(65848.7891) tensor(1740380.1250)\n",
      "Number of net: 1 tensor(1830214.) tensor(33719.5703) tensor(1796494.3750)\n",
      "Number of net: 1 tensor(1805819.2500) tensor(64859.2109) tensor(1740960.)\n",
      "Number of net: 2 tensor(1847584.6250) tensor(48891.5039) tensor(1798693.1250)\n",
      "Number of net: 2 tensor(1790177.) tensor(45110.0508) tensor(1745067.)\n",
      "end of epoch:  1\n",
      "Number of net: 0\n",
      "tensor(17214.7402, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(17211.1367, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(17262.0918, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(1713249.8750) tensor(45820.1484) tensor(1667429.7500)\n",
      "Number of net: 0 tensor(1661972.5000) tensor(46739.3516) tensor(1615233.1250)\n",
      "Number of net: 1 tensor(1694733.3750) tensor(29882.6191) tensor(1664850.7500)\n",
      "Number of net: 1 tensor(1660942.) tensor(50631.8789) tensor(1610310.1250)\n",
      "Number of net: 2 tensor(1722893.2500) tensor(47746.0625) tensor(1675147.1250)\n",
      "Number of net: 2 tensor(1670175.5000) tensor(46796.7109) tensor(1623378.7500)\n",
      "end of epoch:  2\n",
      "Number of net: 0\n",
      "tensor(15963.1914, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(15912.4951, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(16045.0449, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(1599105.1250) tensor(53477.1992) tensor(1545627.8750)\n",
      "Number of net: 0 tensor(1534519.) tensor(36386.3008) tensor(1498132.7500)\n",
      "Number of net: 1 tensor(1592011.2500) tensor(54979.2070) tensor(1537032.)\n",
      "Number of net: 1 tensor(1530567.1250) tensor(44247.5273) tensor(1486319.6250)\n",
      "Number of net: 2 tensor(1588298.) tensor(35487.1523) tensor(1552810.8750)\n",
      "Number of net: 2 tensor(1544657.5000) tensor(41380.9688) tensor(1503276.5000)\n",
      "end of epoch:  3\n",
      "Number of net: 0\n",
      "tensor(14805.6094, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(14684.4980, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(14856.7881, grad_fn=<AddBackward0>)\n",
      "Number of net: 0 tensor(1478545.7500) tensor(44464.6914) tensor(1434081.)\n",
      "Number of net: 0 tensor(1481446.2500) tensor(91022.5781) tensor(1390423.6250)\n",
      "Number of net: 1 tensor(1461804.3750) tensor(41669.3516) tensor(1420135.)\n",
      "Number of net: 1 tensor(1414371.2500) tensor(44013.7773) tensor(1370357.5000)\n",
      "Number of net: 2 tensor(1483255.2500) tensor(45880.4297) tensor(1437374.8750)\n",
      "Number of net: 2 tensor(1434842.3750) tensor(44291.6016) tensor(1390550.7500)\n",
      "end of epoch:  4\n",
      "Number of net: 0\n",
      "tensor(13748.3115, grad_fn=<AddBackward0>)\n",
      "Number of net: 1\n",
      "tensor(13537.9570, grad_fn=<AddBackward0>)\n",
      "Number of net: 2\n",
      "tensor(13739.0469, grad_fn=<AddBackward0>)\n",
      "[array([[2.20304777e-04, 4.60280180e-02, 3.23598720e-02, ...,\n",
      "        2.13641189e-02, 9.73892026e-03, 2.09948316e-01],\n",
      "       [1.21036604e-01, 7.95401692e-01, 2.92642295e-01, ...,\n",
      "        2.01299302e-02, 5.57941431e-03, 4.15550619e-01],\n",
      "       [3.45382929e-01, 9.83070657e-02, 1.99466129e-03, ...,\n",
      "        2.29647513e-02, 5.79514960e-03, 1.28858423e+00],\n",
      "       ...,\n",
      "       [1.12541355e-01, 6.04639128e-02, 9.49590094e-03, ...,\n",
      "        2.30735559e-02, 5.53626334e-03, 1.74760431e-01],\n",
      "       [1.85912237e-01, 9.00548473e-02, 1.06393639e-02, ...,\n",
      "        6.81534002e-04, 9.22069792e-03, 6.85512205e-04],\n",
      "       [7.92347193e-01, 2.16975987e-01, 1.53472868e-03, ...,\n",
      "        2.84777600e-02, 5.23409713e-03, 2.26593111e-02]], dtype=float32), array([[1.1803727e-01, 3.1754562e-01, 8.4416449e-02, ..., 2.3237586e-01,\n",
      "        5.1503408e-01, 2.6752558e-03],\n",
      "       [1.8790073e-03, 1.6238140e-01, 4.1356438e-01, ..., 4.6934113e-01,\n",
      "        1.1368154e-04, 3.7224847e-03],\n",
      "       [1.3108689e-02, 3.8555929e-01, 5.0733691e-01, ..., 4.2796057e-01,\n",
      "        6.4440973e-02, 3.3687910e-03],\n",
      "       ...,\n",
      "       [1.4730565e-01, 9.3560450e-02, 2.4274872e-01, ..., 2.0466049e-01,\n",
      "        1.1103298e-03, 3.1294380e-03],\n",
      "       [1.0582209e-02, 2.5826411e-02, 7.4706650e-01, ..., 1.5191706e-01,\n",
      "        2.4424903e-02, 1.0690637e-03],\n",
      "       [4.3717703e-01, 1.5148793e-01, 1.9861354e-02, ..., 2.0121301e-02,\n",
      "        9.1614556e-01, 3.4738171e-03]], dtype=float32), array([[1.61660731e-01, 2.10621059e-02, 1.85367244e-03, ...,\n",
      "        3.35696936e-02, 4.48638909e-02, 3.37875150e-02],\n",
      "       [2.06042171e-01, 1.11827105e-01, 1.58288085e-03, ...,\n",
      "        9.64511484e-02, 1.42976582e-01, 1.07387662e-01],\n",
      "       [3.13588768e-01, 1.42907515e-01, 1.92534307e-03, ...,\n",
      "        2.63862219e-02, 1.27366831e-04, 1.13973737e-01],\n",
      "       ...,\n",
      "       [2.99547017e-01, 1.15879858e-02, 1.50358083e-03, ...,\n",
      "        3.06711253e-02, 7.15947092e-01, 5.45834750e-03],\n",
      "       [2.00295016e-01, 1.15044042e-02, 2.29903893e-03, ...,\n",
      "        3.05143036e-02, 5.74458897e-01, 2.87913531e-02],\n",
      "       [2.38932535e-01, 6.62746310e-01, 2.08685477e-03, ...,\n",
      "        3.05814240e-02, 2.28605222e-05, 8.69317129e-02]], dtype=float32)]\n",
      "[array([[2.20304777e-04, 4.60280180e-02, 3.23598720e-02, ...,\n",
      "        2.13641189e-02, 9.73892026e-03, 2.09948316e-01],\n",
      "       [1.21036604e-01, 7.95401692e-01, 2.92642295e-01, ...,\n",
      "        2.01299302e-02, 5.57941431e-03, 4.15550619e-01],\n",
      "       [3.45382929e-01, 9.83070657e-02, 1.99466129e-03, ...,\n",
      "        2.29647513e-02, 5.79514960e-03, 1.28858423e+00],\n",
      "       ...,\n",
      "       [1.12541355e-01, 6.04639128e-02, 9.49590094e-03, ...,\n",
      "        2.30735559e-02, 5.53626334e-03, 1.74760431e-01],\n",
      "       [1.85912237e-01, 9.00548473e-02, 1.06393639e-02, ...,\n",
      "        6.81534002e-04, 9.22069792e-03, 6.85512205e-04],\n",
      "       [7.92347193e-01, 2.16975987e-01, 1.53472868e-03, ...,\n",
      "        2.84777600e-02, 5.23409713e-03, 2.26593111e-02]], dtype=float32), array([[1.1803727e-01, 3.1754562e-01, 8.4416449e-02, ..., 2.3237586e-01,\n",
      "        5.1503408e-01, 2.6752558e-03],\n",
      "       [1.8790073e-03, 1.6238140e-01, 4.1356438e-01, ..., 4.6934113e-01,\n",
      "        1.1368154e-04, 3.7224847e-03],\n",
      "       [1.3108689e-02, 3.8555929e-01, 5.0733691e-01, ..., 4.2796057e-01,\n",
      "        6.4440973e-02, 3.3687910e-03],\n",
      "       ...,\n",
      "       [1.4730565e-01, 9.3560450e-02, 2.4274872e-01, ..., 2.0466049e-01,\n",
      "        1.1103298e-03, 3.1294380e-03],\n",
      "       [1.0582209e-02, 2.5826411e-02, 7.4706650e-01, ..., 1.5191706e-01,\n",
      "        2.4424903e-02, 1.0690637e-03],\n",
      "       [4.3717703e-01, 1.5148793e-01, 1.9861354e-02, ..., 2.0121301e-02,\n",
      "        9.1614556e-01, 3.4738171e-03]], dtype=float32), array([[1.61660731e-01, 2.10621059e-02, 1.85367244e-03, ...,\n",
      "        3.35696936e-02, 4.48638909e-02, 3.37875150e-02],\n",
      "       [2.06042171e-01, 1.11827105e-01, 1.58288085e-03, ...,\n",
      "        9.64511484e-02, 1.42976582e-01, 1.07387662e-01],\n",
      "       [3.13588768e-01, 1.42907515e-01, 1.92534307e-03, ...,\n",
      "        2.63862219e-02, 1.27366831e-04, 1.13973737e-01],\n",
      "       ...,\n",
      "       [2.99547017e-01, 1.15879858e-02, 1.50358083e-03, ...,\n",
      "        3.06711253e-02, 7.15947092e-01, 5.45834750e-03],\n",
      "       [2.00295016e-01, 1.15044042e-02, 2.29903893e-03, ...,\n",
      "        3.05143036e-02, 5.74458897e-01, 2.87913531e-02],\n",
      "       [2.38932535e-01, 6.62746310e-01, 2.08685477e-03, ...,\n",
      "        3.05814240e-02, 2.28605222e-05, 8.69317129e-02]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(1.)\n",
      "nonzero params:  tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8774000000000001\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.9425)\n",
      "nonzero params:  tensor(0.9446)\n",
      "0.876\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.8515)\n",
      "nonzero params:  tensor(0.8593)\n",
      "0.8740333333333333\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.7452)\n",
      "nonzero params:  tensor(0.7724)\n",
      "0.8717666666666668\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.6489)\n",
      "nonzero params:  tensor(0.6587)\n",
      "0.8599\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.5511)\n",
      "nonzero params:  tensor(0.5457)\n",
      "0.8496666666666667\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.4411)\n",
      "nonzero params:  tensor(0.4261)\n",
      "0.8282333333333334\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.3337)\n",
      "nonzero params:  tensor(0.3231)\n",
      "0.8153\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.2136)\n",
      "nonzero params:  tensor(0.2059)\n",
      "0.7950333333333334\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.0996)\n",
      "nonzero params:  tensor(0.1106)\n",
      "0.7095333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f731596f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k,lam in enumerate(lamb):\n",
    "    acc_delete = [] \n",
    "    nets = []\n",
    "    optimizer_nets = []\n",
    "    mu = []\n",
    "    sigma = []\n",
    "    prune_coef = []\n",
    "    init_nets()\n",
    "    train_nets()\n",
    "    #graph_loss_func()\n",
    "    init_coeff()\n",
    "    delete_10()\n",
    "    graph()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.6936382e-01, 1.0640321e+00, 5.7452932e-02, ..., 6.7602813e-01,\n",
      "        1.3789254e-02, 1.5713231e-01],\n",
      "       [7.1855374e-02, 7.0443940e-01, 2.6623064e-03, ..., 6.2368882e-01,\n",
      "        8.2746518e-01, 1.3216255e+00],\n",
      "       [6.9820946e-01, 1.3170063e-01, 2.1695089e-01, ..., 7.4240476e-02,\n",
      "        8.9227721e-02, 2.1992934e+00],\n",
      "       ...,\n",
      "       [4.7082552e-01, 1.8184975e+00, 3.4246358e-01, ..., 1.4228056e-01,\n",
      "        7.5836319e-01, 1.6449578e-01],\n",
      "       [5.4279274e-01, 3.0362649e+00, 1.3113405e+00, ..., 1.3760267e+00,\n",
      "        1.7842611e-02, 4.1094947e-01],\n",
      "       [2.0830789e-01, 3.2988248e+00, 2.7313893e+00, ..., 1.9576693e-02,\n",
      "        6.1738282e-02, 1.8082861e+00]], dtype=float32), array([[3.6328045e-01, 1.6444086e+00, 2.5399778e+00, ..., 8.5829598e-01,\n",
      "        8.1680202e-01, 1.4564714e-01],\n",
      "       [3.6823338e-01, 9.7499579e-02, 3.0316523e-01, ..., 1.7589324e+00,\n",
      "        3.7940958e-01, 9.2497449e-03],\n",
      "       [3.6019866e+00, 7.3937815e-01, 9.9103969e-01, ..., 2.2290082e+00,\n",
      "        1.5443812e-01, 2.0868980e-04],\n",
      "       ...,\n",
      "       [1.4743059e-04, 8.0250484e-01, 3.9578149e-01, ..., 1.9010568e+00,\n",
      "        1.7043179e-01, 1.5034150e+00],\n",
      "       [1.6020380e-01, 2.5041791e-02, 2.0053990e-01, ..., 9.2883217e-01,\n",
      "        1.4443141e-01, 1.4828863e-02],\n",
      "       [2.8927633e-04, 3.0352013e+00, 5.9828572e-02, ..., 2.5365102e+00,\n",
      "        1.2227856e+00, 7.8901872e-02]], dtype=float32), array([[1.7211629e+00, 1.4538341e+00, 1.4454928e-01, ..., 1.7716417e+00,\n",
      "        8.0668533e-01, 4.4307403e-02],\n",
      "       [3.6310778e+00, 1.4647824e+00, 4.4001319e-02, ..., 3.5700935e-01,\n",
      "        3.7360051e+00, 1.9427676e+00],\n",
      "       [1.3831136e-04, 2.1402821e-01, 2.5445980e-01, ..., 3.7952662e-01,\n",
      "        8.3922766e-02, 3.0408217e-02],\n",
      "       ...,\n",
      "       [2.3156850e+00, 2.3826431e-02, 5.5419095e-03, ..., 6.1842424e-01,\n",
      "        9.0978557e-01, 7.8078789e-01],\n",
      "       [3.7693622e+00, 2.8268757e-01, 3.0336542e+00, ..., 1.5813354e+00,\n",
      "        2.0812838e-01, 1.3522863e+00],\n",
      "       [3.5777099e-02, 9.2784369e-01, 2.4025526e+00, ..., 2.1622088e-02,\n",
      "        1.2940916e-01, 1.4574101e+00]], dtype=float32)]\n",
      "[array([[2.6936382e-01, 1.0640321e+00, 5.7452932e-02, ..., 6.7602813e-01,\n",
      "        1.3789254e-02, 1.5713231e-01],\n",
      "       [7.1855374e-02, 7.0443940e-01, 2.6623064e-03, ..., 6.2368882e-01,\n",
      "        8.2746518e-01, 1.3216255e+00],\n",
      "       [6.9820946e-01, 1.3170063e-01, 2.1695089e-01, ..., 7.4240476e-02,\n",
      "        8.9227721e-02, 2.1992934e+00],\n",
      "       ...,\n",
      "       [4.7082552e-01, 1.8184975e+00, 3.4246358e-01, ..., 1.4228056e-01,\n",
      "        7.5836319e-01, 1.6449578e-01],\n",
      "       [5.4279274e-01, 3.0362649e+00, 1.3113405e+00, ..., 1.3760267e+00,\n",
      "        1.7842611e-02, 4.1094947e-01],\n",
      "       [2.0830789e-01, 3.2988248e+00, 2.7313893e+00, ..., 1.9576693e-02,\n",
      "        6.1738282e-02, 1.8082861e+00]], dtype=float32), array([[3.6328045e-01, 1.6444086e+00, 2.5399778e+00, ..., 8.5829598e-01,\n",
      "        8.1680202e-01, 1.4564714e-01],\n",
      "       [3.6823338e-01, 9.7499579e-02, 3.0316523e-01, ..., 1.7589324e+00,\n",
      "        3.7940958e-01, 9.2497449e-03],\n",
      "       [3.6019866e+00, 7.3937815e-01, 9.9103969e-01, ..., 2.2290082e+00,\n",
      "        1.5443812e-01, 2.0868980e-04],\n",
      "       ...,\n",
      "       [1.4743059e-04, 8.0250484e-01, 3.9578149e-01, ..., 1.9010568e+00,\n",
      "        1.7043179e-01, 1.5034150e+00],\n",
      "       [1.6020380e-01, 2.5041791e-02, 2.0053990e-01, ..., 9.2883217e-01,\n",
      "        1.4443141e-01, 1.4828863e-02],\n",
      "       [2.8927633e-04, 3.0352013e+00, 5.9828572e-02, ..., 2.5365102e+00,\n",
      "        1.2227856e+00, 7.8901872e-02]], dtype=float32), array([[1.7211629e+00, 1.4538341e+00, 1.4454928e-01, ..., 1.7716417e+00,\n",
      "        8.0668533e-01, 4.4307403e-02],\n",
      "       [3.6310778e+00, 1.4647824e+00, 4.4001319e-02, ..., 3.5700935e-01,\n",
      "        3.7360051e+00, 1.9427676e+00],\n",
      "       [1.3831136e-04, 2.1402821e-01, 2.5445980e-01, ..., 3.7952662e-01,\n",
      "        8.3922766e-02, 3.0408217e-02],\n",
      "       ...,\n",
      "       [2.3156850e+00, 2.3826431e-02, 5.5419095e-03, ..., 6.1842424e-01,\n",
      "        9.0978557e-01, 7.8078789e-01],\n",
      "       [3.7693622e+00, 2.8268757e-01, 3.0336542e+00, ..., 1.5813354e+00,\n",
      "        2.0812838e-01, 1.3522863e+00],\n",
      "       [3.5777099e-02, 9.2784369e-01, 2.4025526e+00, ..., 2.1622088e-02,\n",
      "        1.2940916e-01, 1.4574101e+00]], dtype=float32)]\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(0.9999)\n",
      "nonzero params:  tensor(1.)\n",
      "0.8830666666666667\n",
      "nonzero params:  tensor(0.8999)\n",
      "nonzero params:  tensor(0.8964)\n",
      "nonzero params:  tensor(0.8943)\n",
      "0.8824000000000001\n",
      "nonzero params:  tensor(0.7999)\n",
      "nonzero params:  tensor(0.8017)\n",
      "nonzero params:  tensor(0.8011)\n",
      "0.8815333333333334\n",
      "nonzero params:  tensor(0.6999)\n",
      "nonzero params:  tensor(0.6897)\n",
      "nonzero params:  tensor(0.6963)\n",
      "0.8832\n",
      "nonzero params:  tensor(0.5999)\n",
      "nonzero params:  tensor(0.5856)\n",
      "nonzero params:  tensor(0.5899)\n",
      "0.8848333333333332\n",
      "nonzero params:  tensor(0.4999)\n",
      "nonzero params:  tensor(0.4787)\n",
      "nonzero params:  tensor(0.4944)\n",
      "0.8836333333333334\n",
      "nonzero params:  tensor(0.3999)\n",
      "nonzero params:  tensor(0.3889)\n",
      "nonzero params:  tensor(0.4048)\n",
      "0.8826\n",
      "nonzero params:  tensor(0.2999)\n",
      "nonzero params:  tensor(0.2820)\n",
      "nonzero params:  tensor(0.2983)\n",
      "0.8776333333333334\n",
      "nonzero params:  tensor(0.1999)\n",
      "nonzero params:  tensor(0.1869)\n",
      "nonzero params:  tensor(0.1935)\n",
      "0.8211\n",
      "nonzero params:  tensor(0.0999)\n",
      "nonzero params:  tensor(0.0941)\n",
      "nonzero params:  tensor(0.0983)\n",
      "0.6068666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_coeff()\n",
    "delete_10()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
